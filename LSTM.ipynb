{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INSTRUCTION TO RUN THE CODE:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Training and Testing**\n",
        "\n",
        "\n",
        "\n",
        "*   **Loading Dataset** : Load the dataset for training and give path of the dataset at 'Data Processing block' for reading the dataset.\n",
        "*   **Testing Dataset** : For testing yor csv file you have to load your test_dataset.csv file and provide its path to the block 'preprocessing of test Dataset'.\n",
        "\n",
        "\n",
        "*   For removing stopword you have to upload one extra file final_stopwords.tx and provide its correct path\n",
        "\n",
        "\n",
        "\n",
        "2.   **Loading trained Model and Test:**\n",
        "\n",
        "\n",
        "*   You can test your test csv by just loading the already saved trained model lstm_model.pth that reduce training time\n"
      ],
      "metadata": {
        "id": "tuyF8znf6JT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnZ5odyBPAPF",
        "outputId": "f163ac01-cd46-4c0e-a4c5-6b31e2941115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2CqJ7x8f7zl"
      },
      "source": [
        "# Installing Neccesary library"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "5k-9ngYrx-cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "print(locale.getdefaultlocale())\n",
        "print(locale.getpreferredencoding())"
      ],
      "metadata": {
        "id": "J2KbnRZYyIpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c20c87-abee-4da6-c536-bc890ff65bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('en_US', 'UTF-8')\n",
            "UTF-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJLIGSlPDk_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad275db-f74f-4c17-a03c-f2a0a010f449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.9/dist-packages (0.15.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (0.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata==0.6.0->torchtext) (1.26.15)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (16.0.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchtext) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp39-cp39-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp39-cp39-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext==0.10.0) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.10.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.10.0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (3.4)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.1\n",
            "    Uninstalling torchtext-0.15.1:\n",
            "      Successfully uninstalled torchtext-0.15.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.9.0 torchtext-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for Pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for Pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for Pytorch\n",
            "Failed to build Pytorch\n",
            "Installing collected packages: Pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for Pytorch\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Running setup.py install for Pytorch ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
            "\u001b[31m╰─>\u001b[0m Pytorch\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=352202fd851007625753215f760baf3d252985bf629ea0020aa34e1e570368bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/b8/0f/f580817231cbf59f6ade9fd132ff60ada1de9f7dc85521f857\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.22.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext\n",
        "!pip install torchtext==0.10.0\n",
        "!pip install Pytorch\n",
        "!pip install emoji\n",
        "!pip install nltk\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D06f8yBbgHu1"
      },
      "source": [
        "# Import require Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyh1VNNOgR7J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "import collections\n",
        "from collections import Counter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jZPOD2ghRh1"
      },
      "source": [
        "# Trainig Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1yzpxpZqgc1o",
        "outputId": "de1f6b55-2eaf-417c-8f93-2454272f98af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                       text\n",
              "0      0              भीड़ में  बहुत  हब्सी मिलेंगे\n",
              "1      0  साले बेवकूफ अपनी मां मक्खियां  तो हटा दें\n",
              "2      0           बुर देदो तो मुह में लंड ले लो तो\n",
              "3      0       कुत्ता वहा है चिल्ला तू क्यों रहा है\n",
              "4      1  चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c82eef7c-4f2e-40a5-9eaa-ea0339587641\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>भीड़ में  बहुत  हब्सी मिलेंगे</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>साले बेवकूफ अपनी मां मक्खियां  तो हटा दें</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>बुर देदो तो मुह में लंड ले लो तो</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>कुत्ता वहा है चिल्ला तू क्यों रहा है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c82eef7c-4f2e-40a5-9eaa-ea0339587641')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c82eef7c-4f2e-40a5-9eaa-ea0339587641 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c82eef7c-4f2e-40a5-9eaa-ea0339587641');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Loading the dataset\n",
        "full_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/22CS60R37_A8 DL/hindi_train_val.csv')\n",
        "# df = full_df[[\"text\"]]\n",
        "df = full_df\n",
        "# df[\"text\"] = df[\"text\"].astype(str)\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pSmoyowhxgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988dfdb4-570d-409f-cc16-8b67ba0b5e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indic_transliteration\n",
            "  Downloading indic_transliteration-2.3.44-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting indicnlp\n",
            "  Downloading indicnlp-0.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.91-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting indic\n",
            "  Downloading indic-0.1.2.tar.gz (6.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from indic_transliteration) (2022.10.31)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.9/dist-packages (from indic_transliteration) (0.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from indic_transliteration) (0.10.2)\n",
            "Collecting backports.functools-lru-cache\n",
            "  Downloading backports.functools_lru_cache-1.6.4-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting roman\n",
            "  Downloading roman-4.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.2.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from indic-nlp-library) (1.5.3)\n",
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from indic-nlp-library) (1.22.4)\n",
            "Collecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: matplotlib>=1.3 in /usr/local/lib/python3.9/dist-packages (from indic) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.13 in /usr/local/lib/python3.9/dist-packages (from indic) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.13 in /usr/local/lib/python3.9/dist-packages (from indic) (1.10.1)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (8.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->indic-nlp-library) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.13->indic) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.13->indic) (3.1.0)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from sphinx-argparse->indic-nlp-library) (3.5.4)\n",
            "Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.9/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.16)\n",
            "Collecting sphinxcontrib-jquery!=3.0.0,>=2.0.0\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer->indic_transliteration) (8.1.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=1.3->indic) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3->indic) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (67.6.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.14.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.27.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2022.12.7)\n",
            "Building wheels for collected packages: indic\n",
            "  Building wheel for indic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for indic: filename=indic-0.1.2-py3-none-any.whl size=10089 sha256=77d6979e12d24ad52dd8075948f02b1eeba5f4cac197a3dfad7dc8622c7164e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/46/ae/5111371e0c7d7160c689f9f6cee321acd45a4e32d4c419dd4a\n",
            "Successfully built indic\n",
            "Installing collected packages: morfessor, indicnlp, roman, backports.functools-lru-cache, indic_transliteration, sphinxcontrib-jquery, sphinx-argparse, indic, sphinx-rtd-theme, indic-nlp-library\n",
            "Successfully installed backports.functools-lru-cache-1.6.4 indic-0.1.2 indic-nlp-library-0.91 indic_transliteration-2.3.44 indicnlp-0.0.1 morfessor-2.0.6 roman-4.0 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.2.0 sphinxcontrib-jquery-4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install indic_transliteration indicnlp indic-nlp-library indic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vne2RApogtH6"
      },
      "outputs": [],
      "source": [
        "from indicnlp.tokenize import indic_tokenize\n",
        "def tokenization(indic_string):\n",
        "    tokens = []\n",
        "    for t in indic_tokenize.trivial_tokenize(indic_string):\n",
        "        tokens.append(t)\n",
        "    return tokens\n",
        "df['text'] = df['text'].apply(lambda x: tokenization(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxNJ0j70g0QN"
      },
      "outputs": [],
      "source": [
        "# stopword list\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/22CS60R37_A8 DL/final_stopwords.txt', 'r', encoding=\"utf8\") as file:\n",
        "    content = file.readlines()\n",
        "\n",
        "stopwords_hi = [line.strip() for line in content]\n",
        "\n",
        "# stopwords_hi = ['तुम','मेरी','मुझे','क्योंकि','हम','प्रति','अबकी','आगे','माननीय','शहर','बताएं','कौनसी','क्लिक','किसकी','बड़े','मैं','and','रही','आज','लें','आपके','मिलकर','सब','मेरे','जी','श्री','वैसा','आपका','अंदर', 'अत', 'अपना', 'अपनी', 'अपने', 'अभी', 'आदि', 'आप', 'इत्यादि', 'इन', 'इनका', 'इन्हीं', 'इन्हें', 'इन्हों', 'इस', 'इसका', 'इसकी', 'इसके', 'इसमें', 'इसी', 'इसे', 'उन', 'उनका', 'उनकी', 'उनके', 'उनको', 'उन्हीं', 'उन्हें', 'उन्हों', 'उस', 'उसके', 'उसी', 'उसे', 'एक', 'एवं', 'एस', 'ऐसे', 'और', 'कई', 'कर','करता', 'करते', 'करना', 'करने', 'करें', 'कहते', 'कहा', 'का', 'काफ़ी', 'कि', 'कितना', 'किन्हें', 'किन्हों', 'किया', 'किर', 'किस', 'किसी', 'किसे', 'की', 'कुछ', 'कुल', 'के', 'को', 'कोई', 'कौन', 'कौनसा', 'गया', 'घर', 'जब', 'जहाँ', 'जा', 'जितना', 'जिन', 'जिन्हें', 'जिन्हों', 'जिस', 'जिसे', 'जीधर', 'जैसा', 'जैसे', 'जो', 'तक', 'तब', 'तरह', 'तिन', 'तिन्हें', 'तिन्हों', 'तिस', 'तिसे', 'तो', 'था', 'थी', 'थे', 'दबारा', 'दिया', 'दुसरा', 'दूसरे', 'दो', 'द्वारा', 'न', 'नहीं', 'ना', 'निहायत', 'नीचे', 'ने', 'पर', 'पर', 'पहले', 'पूरा', 'पे', 'फिर', 'बनी', 'बही', 'बहुत', 'बाद', 'बाला', 'बिलकुल', 'भी', 'भीतर', 'मगर', 'मानो', 'मे', 'में', 'यदि', 'यह', 'यहाँ', 'यही', 'या', 'यिह', 'ये', 'रखें', 'रहा', 'रहे', 'ऱ्वासा', 'लिए', 'लिये', 'लेकिन', 'व', 'वर्ग', 'वह', 'वह', 'वहाँ', 'वहीं', 'वाले', 'वुह', 'वे', 'वग़ैरह', 'संग', 'सकता', 'सकते', 'सबसे', 'सभी', 'साथ', 'साबुत', 'साभ', 'सारा', 'से', 'सो', 'ही', 'हुआ', 'हुई', 'हुए', 'है', 'हैं', 'हो', 'होता', 'होती', 'होते', 'होना', 'होने', 'अपनि', 'जेसे', 'होति', 'सभि', 'तिंहों', 'इंहों', 'दवारा', 'इसि', 'किंहें', 'थि', 'उंहों', 'ओर', 'जिंहें', 'वहिं', 'अभि', 'बनि', 'हि', 'उंहिं', 'उंहें', 'हें', 'वगेरह', 'एसे', 'रवासा', 'कोन', 'निचे', 'काफि', 'उसि', 'पुरा', 'भितर', 'हे', 'बहि', 'वहां', 'कोइ', 'यहां', 'जिंहों', 'तिंहें', 'किसि', 'कइ', 'यहि', 'इंहिं', 'जिधर', 'इंहें', 'अदि', 'इतयादि', 'हुइ', 'कोनसा', 'इसकि', 'दुसरे', 'जहां', 'अप', 'किंहों', 'उनकि', 'भि', 'वरग', 'हुअ', 'जेसा', 'नहिं']\n",
        "stopwords_en = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "# punctuations = ['nn','n', '।','/', '`', '+', '\\', '\"', '?', '▁(', '$', '@', '[', '_', \"'\", '!', ',', ':', '^', '|', ']', '=', '%', '&', '.', ')', '(', '#', '*', '', ';', '-', '}','|','\"']\n",
        "\n",
        "# punctuations = ['(', ')', '?', ':', ';', ',', '.', '!', '/', '\"', \"'\"]\n",
        "\n",
        "punctuations = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"-\", \"—\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"/\", \"\\\\\", \"|\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"*\", \"+\", \"=\", \"<\", \">\", \"_\", \"~\", \"`\", \"'\", \"\\\"\", \"«\", \"»\", \"“\", \"”\", \"‘\", \"’\", \"‹\", \"›\", \"„\", \"‟\", \"‛\", \"‟\", \"‘\", \"’\", \"‚\", \"‛\", \"‟\", \"‹\", \"›\", \"〈\", \"〉\", \"《\", \"》\", \"「\", \"」\", \"『\", \"』\", \"【\", \"】\"]\n",
        "\n",
        "\n",
        "\n",
        "to_be_removed = stopwords_hi + punctuations + stopwords_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Sxm03trTg6ts",
        "outputId": "c9e91832-fd94-48fd-b867-24a1dfdc9617"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                               text\n",
              "20173      0                               [ठोक, तू, अच्छा, ना]\n",
              "20174      1  [💥💥💥, गुड, नाइट, जी💥💥💥💥🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂...\n",
              "20175      0                                   [तेरी, माँ, कसम]\n",
              "20176      1  [जीवन, जीने, के, तरीके, मायने, के, चमत्कार, नह...\n",
              "20177      1                               [तीसरा, नाम्, कल्लू]\n",
              "20178      0                         [छोटे, क्यु, पहनते, जरूरत]\n",
              "20179      1                  [कैसी, सोना, हमसे, दोस्ती, करोगी]\n",
              "20180      1                       [पता, चलता, चुनाव, आ, है🙄🙄🙄]\n",
              "20181      1                 [खेत, जोते, किसान, भैंस, के, साथो]\n",
              "20182      0  [काश, आगर, इतना, दिमाग, पढाई, लगायें, शायद, जा..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30568c85-1f20-4eff-8726-6f3f78e30962\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20173</th>\n",
              "      <td>0</td>\n",
              "      <td>[ठोक, तू, अच्छा, ना]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20174</th>\n",
              "      <td>1</td>\n",
              "      <td>[💥💥💥, गुड, नाइट, जी💥💥💥💥🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20175</th>\n",
              "      <td>0</td>\n",
              "      <td>[तेरी, माँ, कसम]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20176</th>\n",
              "      <td>1</td>\n",
              "      <td>[जीवन, जीने, के, तरीके, मायने, के, चमत्कार, नह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20177</th>\n",
              "      <td>1</td>\n",
              "      <td>[तीसरा, नाम्, कल्लू]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20178</th>\n",
              "      <td>0</td>\n",
              "      <td>[छोटे, क्यु, पहनते, जरूरत]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20179</th>\n",
              "      <td>1</td>\n",
              "      <td>[कैसी, सोना, हमसे, दोस्ती, करोगी]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20180</th>\n",
              "      <td>1</td>\n",
              "      <td>[पता, चलता, चुनाव, आ, है🙄🙄🙄]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20181</th>\n",
              "      <td>1</td>\n",
              "      <td>[खेत, जोते, किसान, भैंस, के, साथो]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20182</th>\n",
              "      <td>0</td>\n",
              "      <td>[काश, आगर, इतना, दिमाग, पढाई, लगायें, शायद, जा...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30568c85-1f20-4eff-8726-6f3f78e30962')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30568c85-1f20-4eff-8726-6f3f78e30962 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30568c85-1f20-4eff-8726-6f3f78e30962');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# removing all stopword\n",
        "\n",
        "for i in range(len(df)):\n",
        "    df['text'][i]=[ele for ele in df['text'][i] if ele not in (to_be_removed)]\n",
        "# count_length()\n",
        "df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "NEXayJywg_Wq",
        "outputId": "5f0a5151-6340-4c17-d50f-94857d85ae50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                               text  \\\n",
              "20173      0                               [ठोक, तू, अच्छा, ना]   \n",
              "20174      1  [💥💥💥, गुड, नाइट, जी💥💥💥💥🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂...   \n",
              "20175      0                                   [तेरी, माँ, कसम]   \n",
              "20176      1  [जीवन, जीने, के, तरीके, मायने, के, चमत्कार, नह...   \n",
              "20177      1                               [तीसरा, नाम्, कल्लू]   \n",
              "20178      0                         [छोटे, क्यु, पहनते, जरूरत]   \n",
              "20179      1                  [कैसी, सोना, हमसे, दोस्ती, करोगी]   \n",
              "20180      1                       [पता, चलता, चुनाव, आ, है🙄🙄🙄]   \n",
              "20181      1                 [खेत, जोते, किसान, भैंस, के, साथो]   \n",
              "20182      0  [काश, आगर, इतना, दिमाग, पढाई, लगायें, शायद, जा...   \n",
              "\n",
              "                                          processed_text  \n",
              "20173                                    ठोक तू अच्छा ना  \n",
              "20174  💥💥💥 गुड नाइट जी💥💥💥💥🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂...  \n",
              "20175                                       तेरी माँ कसम  \n",
              "20176  जीवन जीने के तरीके मायने के चमत्कार नही दुसरे ...  \n",
              "20177                                   तीसरा नाम् कल्लू  \n",
              "20178                              छोटे क्यु पहनते जरूरत  \n",
              "20179                        कैसी सोना हमसे दोस्ती करोगी  \n",
              "20180                             पता चलता चुनाव आ है🙄🙄🙄  \n",
              "20181                        खेत जोते किसान भैंस के साथो  \n",
              "20182  काश आगर इतना दिमाग पढाई लगायें शायद जाकर डॉक्ट...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acf607b1-4f47-4aef-b847-5561bb344061\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20173</th>\n",
              "      <td>0</td>\n",
              "      <td>[ठोक, तू, अच्छा, ना]</td>\n",
              "      <td>ठोक तू अच्छा ना</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20174</th>\n",
              "      <td>1</td>\n",
              "      <td>[💥💥💥, गुड, नाइट, जी💥💥💥💥🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂...</td>\n",
              "      <td>💥💥💥 गुड नाइट जी💥💥💥💥🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂️🙋‍♂...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20175</th>\n",
              "      <td>0</td>\n",
              "      <td>[तेरी, माँ, कसम]</td>\n",
              "      <td>तेरी माँ कसम</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20176</th>\n",
              "      <td>1</td>\n",
              "      <td>[जीवन, जीने, के, तरीके, मायने, के, चमत्कार, नह...</td>\n",
              "      <td>जीवन जीने के तरीके मायने के चमत्कार नही दुसरे ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20177</th>\n",
              "      <td>1</td>\n",
              "      <td>[तीसरा, नाम्, कल्लू]</td>\n",
              "      <td>तीसरा नाम् कल्लू</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20178</th>\n",
              "      <td>0</td>\n",
              "      <td>[छोटे, क्यु, पहनते, जरूरत]</td>\n",
              "      <td>छोटे क्यु पहनते जरूरत</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20179</th>\n",
              "      <td>1</td>\n",
              "      <td>[कैसी, सोना, हमसे, दोस्ती, करोगी]</td>\n",
              "      <td>कैसी सोना हमसे दोस्ती करोगी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20180</th>\n",
              "      <td>1</td>\n",
              "      <td>[पता, चलता, चुनाव, आ, है🙄🙄🙄]</td>\n",
              "      <td>पता चलता चुनाव आ है🙄🙄🙄</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20181</th>\n",
              "      <td>1</td>\n",
              "      <td>[खेत, जोते, किसान, भैंस, के, साथो]</td>\n",
              "      <td>खेत जोते किसान भैंस के साथो</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20182</th>\n",
              "      <td>0</td>\n",
              "      <td>[काश, आगर, इतना, दिमाग, पढाई, लगायें, शायद, जा...</td>\n",
              "      <td>काश आगर इतना दिमाग पढाई लगायें शायद जाकर डॉक्ट...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acf607b1-4f47-4aef-b847-5561bb344061')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acf607b1-4f47-4aef-b847-5561bb344061 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acf607b1-4f47-4aef-b847-5561bb344061');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Converting list to string \n",
        "\n",
        "# Create a new column called 'processed_text'\n",
        "df['processed_text'] = ''\n",
        "\n",
        "# Iterate over each row of the DataFrame\n",
        "for i in range(len(df)):\n",
        "    # Join the list of strings in the 'text' column with a space separator\n",
        "    text_string = ' '.join(df['text'][i])\n",
        "    # Remove the stopwords from the text string\n",
        "    text_string = ' '.join([word for word in text_string.split() if word.lower() not in to_be_removed])\n",
        "    # Update the 'processed_text' column with the processed text string\n",
        "    df.loc[i, 'processed_text'] = text_string\n",
        "\n",
        "# # Call the count_length() function (assuming it's defined somewhere)\n",
        "# count_length()\n",
        "\n",
        "df.tail(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindf, valdf = train_test_split(df,train_size=0.8)"
      ],
      "metadata": {
        "id": "NCWklakE-cuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Test Dataset"
      ],
      "metadata": {
        "id": "n5VdOMHW52-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/22CS60R37_A8 DL/hindi_test.csv')\n",
        "# df = full_df[[\"text\"]]\n",
        "tdf = test_df\n",
        "# df[\"text\"] = df[\"text\"].astype(str)\n",
        "tdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JyHN9SiP5xMt",
        "outputId": "a04f70b8-f4a5-44c7-b56a-03162d1e9cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  मैं ये नही सोच रहा की इसे निकले कैसे मैं ये सो...\n",
              "1      1        और दिवाली में भी पूरा देश पड़ाका नहीं फोडात\n",
              "2      1      कुत्ता बिल्ली पाल लेना मगर गलत फहमी कभी नहीं।\n",
              "3      0      तेरी गांड में प्याज काट देगा गुज्जर भोसड़ी के\n",
              "4      1            बंगाली साड़ी ऐसे नहीं पहना जाता है दीदी"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd97f982-5e01-4f33-b2fc-68aeb5295f9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>मैं ये नही सोच रहा की इसे निकले कैसे मैं ये सो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>और दिवाली में भी पूरा देश पड़ाका नहीं फोडात</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>कुत्ता बिल्ली पाल लेना मगर गलत फहमी कभी नहीं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>तेरी गांड में प्याज काट देगा गुज्जर भोसड़ी के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>बंगाली साड़ी ऐसे नहीं पहना जाता है दीदी</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd97f982-5e01-4f33-b2fc-68aeb5295f9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd97f982-5e01-4f33-b2fc-68aeb5295f9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd97f982-5e01-4f33-b2fc-68aeb5295f9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from indicnlp.tokenize import indic_tokenize\n",
        "def tokenization(indic_string):\n",
        "    tokens = []\n",
        "    for t in indic_tokenize.trivial_tokenize(indic_string):\n",
        "        tokens.append(t)\n",
        "    return tokens\n",
        "tdf['text'] = tdf['text'].apply(lambda x: tokenization(x))\n",
        "\n",
        "# removing all stopword\n",
        "\n",
        "for i in range(len(tdf)):\n",
        "    tdf['text'][i]=[ele for ele in tdf['text'][i] if ele not in (to_be_removed)]\n",
        "# count_length()\n",
        "# tdf.tail(10)\n",
        "\n",
        "# Converting list to string \n",
        "\n",
        "# Create a new column called 'processed_text'\n",
        "tdf['tprocessed_text'] = ''\n",
        "\n",
        "# Iterate over each row of the DataFrame\n",
        "for i in range(len(tdf)):\n",
        "    # Join the list of strings in the 'text' column with a space separator\n",
        "    text_string = ' '.join(tdf['text'][i])\n",
        "    # Remove the stopwords from the text string\n",
        "    text_string = ' '.join([word for word in text_string.split() if word.lower() not in to_be_removed])\n",
        "    # Update the 'processed_text' column with the processed text string\n",
        "    tdf.loc[i, 'tprocessed_text'] = text_string\n",
        "\n",
        "# Call the count_length() function (assuming it's defined somewhere)\n",
        "# count_length()\n",
        "\n",
        "tdf.tail(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EpOQK8Zl58sq",
        "outputId": "87acf022-a4b4-4242-8ba5-68369fc03687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text  \\\n",
              "6718      0                  [चूतियो, कमी, नहीं, बढ़कर, चुतिय]   \n",
              "6719      0  [प्यार❤, व्यार, 💔साला, सब, धोखा, 😡है, बिना, जि...   \n",
              "6720      0           [नंगी, होकर, वीडियो, बनाओ, अच्छी, लगोगी]   \n",
              "6721      0  [सही, तरीके, कपड़े, दिखाने, के, मेरे, पास, कपड़ा]   \n",
              "6722      1  [बीजेपी, देन, मंदिर, सब, मंदिर, रुकवाने, कसर, ...   \n",
              "6723      0                [आरे, पागल, लवडे, समज, आये, वो, ना]   \n",
              "6724      0  [शेर, नज़र, अंदाज़, ।, कमजोरी, मत, समझ, लेना, तु...   \n",
              "6725      0                        [लाल, चड्डी, के, लाल, होगा]   \n",
              "6726      1                                                 []   \n",
              "6727      0  [पोरीच्या, फोटो, काय, महाराजांचे, नाटक, रे, मा...   \n",
              "\n",
              "                                        tprocessed_text  \n",
              "6718                        चूतियो कमी नहीं बढ़कर चुतिय  \n",
              "6719  प्यार❤ व्यार 💔साला सब धोखा 😡है बिना जिंदगी 🌎जी...  \n",
              "6720                  नंगी होकर वीडियो बनाओ अच्छी लगोगी  \n",
              "6721           सही तरीके कपड़े दिखाने के मेरे पास कपड़ा  \n",
              "6722  बीजेपी देन मंदिर सब मंदिर रुकवाने कसर नहीं छोड...  \n",
              "6723                        आरे पागल लवडे समज आये वो ना  \n",
              "6724  शेर नज़र अंदाज़ । कमजोरी मत समझ लेना तुम्हारे कौ...  \n",
              "6725                              लाल चड्डी के लाल होगा  \n",
              "6726                                                     \n",
              "6727       पोरीच्या फोटो काय महाराजांचे नाटक रे मादरचोत  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14172312-0c28-4478-9581-4663eca0c5f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>tprocessed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6718</th>\n",
              "      <td>0</td>\n",
              "      <td>[चूतियो, कमी, नहीं, बढ़कर, चुतिय]</td>\n",
              "      <td>चूतियो कमी नहीं बढ़कर चुतिय</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6719</th>\n",
              "      <td>0</td>\n",
              "      <td>[प्यार❤, व्यार, 💔साला, सब, धोखा, 😡है, बिना, जि...</td>\n",
              "      <td>प्यार❤ व्यार 💔साला सब धोखा 😡है बिना जिंदगी 🌎जी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6720</th>\n",
              "      <td>0</td>\n",
              "      <td>[नंगी, होकर, वीडियो, बनाओ, अच्छी, लगोगी]</td>\n",
              "      <td>नंगी होकर वीडियो बनाओ अच्छी लगोगी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6721</th>\n",
              "      <td>0</td>\n",
              "      <td>[सही, तरीके, कपड़े, दिखाने, के, मेरे, पास, कपड़ा]</td>\n",
              "      <td>सही तरीके कपड़े दिखाने के मेरे पास कपड़ा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722</th>\n",
              "      <td>1</td>\n",
              "      <td>[बीजेपी, देन, मंदिर, सब, मंदिर, रुकवाने, कसर, ...</td>\n",
              "      <td>बीजेपी देन मंदिर सब मंदिर रुकवाने कसर नहीं छोड...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6723</th>\n",
              "      <td>0</td>\n",
              "      <td>[आरे, पागल, लवडे, समज, आये, वो, ना]</td>\n",
              "      <td>आरे पागल लवडे समज आये वो ना</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6724</th>\n",
              "      <td>0</td>\n",
              "      <td>[शेर, नज़र, अंदाज़, ।, कमजोरी, मत, समझ, लेना, तु...</td>\n",
              "      <td>शेर नज़र अंदाज़ । कमजोरी मत समझ लेना तुम्हारे कौ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6725</th>\n",
              "      <td>0</td>\n",
              "      <td>[लाल, चड्डी, के, लाल, होगा]</td>\n",
              "      <td>लाल चड्डी के लाल होगा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6726</th>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6727</th>\n",
              "      <td>0</td>\n",
              "      <td>[पोरीच्या, फोटो, काय, महाराजांचे, नाटक, रे, मा...</td>\n",
              "      <td>पोरीच्या फोटो काय महाराजांचे नाटक रे मादरचोत</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14172312-0c28-4478-9581-4663eca0c5f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14172312-0c28-4478-9581-4663eca0c5f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14172312-0c28-4478-9581-4663eca0c5f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPLEMENTATION OF LSTM"
      ],
      "metadata": {
        "id": "EUmHg2pYBJ_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Tokenize(column, seq_len):\n",
        "    ##Create vocabulary of words from column\n",
        "    corpus = [word for text in df['processed_text'] for word in text.split()]\n",
        "    count_words = Counter(corpus)\n",
        "    sorted_words = count_words.most_common()\n",
        "    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "\n",
        "    ##Tokenize the columns text using the vocabulary\n",
        "    text_int = []\n",
        "    for text in column:\n",
        "        r = [vocab_to_int[word] for word in text.split()]\n",
        "        text_int.append(r)\n",
        "    ##Add padding to tokens\n",
        "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    for i, review in enumerate(text_int):\n",
        "        if len(review) <= seq_len:\n",
        "            zeros = list(np.zeros(seq_len - len(review)))\n",
        "            new = zeros + review\n",
        "        else:\n",
        "            new = review[: seq_len]\n",
        "        features[i, :] = np.array(new)\n",
        "\n",
        "    return sorted_words, features\n",
        "\n"
      ],
      "metadata": {
        "id": "4jbnId0XBH1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=100\n",
        "vocabulary, tokenized_column = Tokenize(df[\"processed_text\"], max_len)"
      ],
      "metadata": {
        "id": "-0uyGy6DrIrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_column[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGI9iX_VrSEa",
        "outputId": "13c502c6-efc6-4d9a-8f0b-edc38c1ce75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1248,\n",
              "       1600])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UrYkS65Fsdj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = df['processed_text']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train)"
      ],
      "metadata": {
        "id": "IhxxLiUfsBx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Word2vec_train_data = list(map(lambda x: x.split(), X_train))\n",
        "EMBEDDING_DIM = 200\n"
      ],
      "metadata": {
        "id": "cBGH2kxyrNPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "AMU9EsrOtCWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = Word2Vec(Word2vec_train_data, vector_size=EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "QCxPK49AsxES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocabulary size: {len(vocabulary) + 1}\")"
      ],
      "metadata": {
        "id": "hnSR_EKYBSVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a520df-94ff-4bd5-b666-f6bea1feb9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 32408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(vocabulary) + 1 #+1 for the padding\n"
      ],
      "metadata": {
        "id": "53ai4TxPtSx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define empty embedding matrix\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
        "    \n",
        "#fill the embedding matrix with the pre trained values from word2vec\n",
        "#    corresponding to word (string), token (number associated to the word)\n",
        "for word, token in vocabulary:\n",
        "    if word2vec_model.wv.__contains__(word):\n",
        "        embedding_matrix[token] = word2vec_model.wv.__getitem__(word)\n",
        "\n",
        "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syju4RlAtfUi",
        "outputId": "6f59359a-3a87-48e1-86f7-de10a0edc1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Matrix Shape: (32408, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "X = tokenized_column\n",
        "y = df['label'].values"
      ],
      "metadata": {
        "id": "Drfdw_yltgxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=42)"
      ],
      "metadata": {
        "id": "zKvjwI5dtteL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcwITdTTt2Xg",
        "outputId": "1dc2cc51-a56e-4ce7-8863-e0a967e47415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0, 7579],\n",
              "       [   1, 6952]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "#Tokenization for LSTM\n",
        "from collections import Counter\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "reWipJqguHmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)) #\n",
        "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True) \n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True) #"
      ],
      "metadata": {
        "id": "xb7HApO9t7JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 5 #We are dealing with a multiclass classification of 5 classes\n",
        "HIDDEN_DIM = 100 #number of neurons of the internal state (internal neural network in the LSTM)\n",
        "LSTM_LAYERS = 1 #Number of stacked LSTM layers\n",
        "\n",
        "LR = 3e-4 #Learning rate\n",
        "DROPOUT = 0.5 #LSTM Dropout\n",
        "BIDIRECTIONAL = True #Boolean value to choose if to use a bidirectional LSTM or not\n",
        "EPOCHS = 10 #Number of training epoch\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "class BiLSTM_Sentiment_Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, lstm_layers, bidirectional,batch_size, dropout):\n",
        "        super(BiLSTM_Sentiment_Classifier,self).__init__()\n",
        "        \n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers=lstm_layers,\n",
        "                            dropout=dropout,\n",
        "                            bidirectional=bidirectional,\n",
        "                            batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim*self.num_directions, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        self.batch_size = x.size(0)\n",
        "        ##EMBEDDING LAYER\n",
        "        embedded = self.embedding(x)\n",
        "        #LSTM LAYERS\n",
        "        out, hidden = self.lstm(embedded, hidden)\n",
        "        #Extract only the hidden state from the last LSTM cell\n",
        "        out = out[:,-1,:]\n",
        "        #FULLY CONNECTED LAYERS\n",
        "        out = self.fc(out)\n",
        "        out = self.softmax(out)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        #Initialization of the LSTM hidden and cell states\n",
        "        h0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n",
        "        c0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n",
        "        hidden = (h0, c0)\n",
        "        return hidden\n",
        "model = BiLSTM_Sentiment_Classifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM,NUM_CLASSES, LSTM_LAYERS,BIDIRECTIONAL, BATCH_SIZE, DROPOUT)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "#Initialize embedding with the previously defined embedding matrix\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "#Allow the embedding matrix to be fined tuned to better adapt to out dataset and get higher accuracy\n",
        "model.embedding.weight.requires_grad=True\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6VB5W0iuTBY",
        "outputId": "96ca60b1-0d23-4bb8-ae3d-4e21463f1d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiLSTM_Sentiment_Classifier(\n",
            "  (embedding): Embedding(32408, 200)\n",
            "  (lstm): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay = 5e-6)"
      ],
      "metadata": {
        "id": "hxkDtJLluo0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Below cell is for trainig if dont want to train dont run it"
      ],
      "metadata": {
        "id": "kC50B-50QeoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "total_step_val = len(valid_loader)\n",
        "\n",
        "early_stopping_patience = 4\n",
        "early_stopping_counter = 0\n",
        "\n",
        "valid_acc_max = 0 # Initialize best accuracy top 0\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "\n",
        "    #lists to host the train and validation losses of every batch for each epoch\n",
        "    train_loss, valid_loss  = [], []\n",
        "    #lists to host the train and validation accuracy of every batch for each epoch\n",
        "    train_acc, valid_acc  = [], []\n",
        "\n",
        "    #lists to host the train and validation predictions of every batch for each epoch\n",
        "    y_train_list, y_val_list = [], []\n",
        "\n",
        "    #initalize number of total and correctly classified texts during training and validation\n",
        "    correct, correct_val = 0, 0\n",
        "    total, total_val = 0, 0\n",
        "    running_loss, running_loss_val = 0, 0\n",
        "\n",
        "\n",
        "    ####TRAINING LOOP####\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE) #load features and targets in device\n",
        "\n",
        "        h = model.init_hidden(labels.size(0))\n",
        "\n",
        "        model.zero_grad() #reset gradients \n",
        "\n",
        "        output, h = model(inputs,h) #get output and hidden states from LSTM network\n",
        "        \n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred_train = torch.argmax(output, dim=1) #get tensor of predicted values on the training set\n",
        "        y_train_list.extend(y_pred_train.squeeze().tolist()) #transform tensor to list and the values to the list\n",
        "        \n",
        "        correct += torch.sum(y_pred_train==labels).item() #count correctly classified texts per batch\n",
        "        total += labels.size(0) #count total texts per batch\n",
        "\n",
        "    train_loss.append(running_loss / total_step)\n",
        "    train_acc.append(100 * correct / total)\n",
        "\n",
        "    ####VALIDATION LOOP####\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        model.eval()\n",
        "        \n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            val_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "\n",
        "            val_loss = criterion(output, labels)\n",
        "            running_loss_val += val_loss.item()\n",
        "\n",
        "            y_pred_val = torch.argmax(output, dim=1)\n",
        "            y_val_list.extend(y_pred_val.squeeze().tolist())\n",
        "\n",
        "            correct_val += torch.sum(y_pred_val==labels).item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "        valid_loss.append(running_loss_val / total_step_val)\n",
        "        valid_acc.append(100 * correct_val / total_val)\n",
        "\n",
        "    #Save model if validation accuracy increases\n",
        "    if np.mean(valid_acc) >= valid_acc_max:\n",
        "        torch.save(model.state_dict(), './lstm_model.pth')\n",
        "        print(f'Epoch {e+1}:Validation accuracy increased ({valid_acc_max:.6f} --> {np.mean(valid_acc):.6f}).  Saving model ...')\n",
        "        valid_acc_max = np.mean(valid_acc)\n",
        "        early_stopping_counter=0 #reset counter if validation accuracy increases\n",
        "    else:\n",
        "        print(f'Epoch {e+1}:Validation accuracy did not increase')\n",
        "        early_stopping_counter+=1 #increase counter if validation accuracy does not increase\n",
        "        \n",
        "    if early_stopping_counter > early_stopping_patience:\n",
        "        print('Early stopped at epoch :', e+1)\n",
        "        break\n",
        "    \n",
        "    print(f'\\tTrain_loss : {np.mean(train_loss):.4f} Val_loss : {np.mean(valid_loss):.4f}')\n",
        "    print(f'\\tTrain_acc : {np.mean(train_acc):.3f}% Val_acc : {np.mean(valid_acc):.3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_5ZLHvGuq6X",
        "outputId": "12c7887e-7bfe-420e-90d5-c70af920c744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:Validation accuracy increased (0.000000 --> 73.312500).  Saving model ...\n",
            "\tTrain_loss : 0.7472 Val_loss : 0.6180\n",
            "\tTrain_acc : 55.789% Val_acc : 73.312%\n",
            "Epoch 2:Validation accuracy increased (73.312500 --> 79.000000).  Saving model ...\n",
            "\tTrain_loss : 0.4364 Val_loss : 0.4484\n",
            "\tTrain_acc : 82.358% Val_acc : 79.000%\n",
            "Epoch 3:Validation accuracy increased (79.000000 --> 80.437500).  Saving model ...\n",
            "\tTrain_loss : 0.2279 Val_loss : 0.4742\n",
            "\tTrain_acc : 91.795% Val_acc : 80.438%\n",
            "Epoch 4:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.1351 Val_loss : 0.4992\n",
            "\tTrain_acc : 95.457% Val_acc : 79.312%\n",
            "Epoch 5:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0875 Val_loss : 0.5679\n",
            "\tTrain_acc : 97.212% Val_acc : 79.750%\n",
            "Epoch 6:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0632 Val_loss : 0.6319\n",
            "\tTrain_acc : 98.259% Val_acc : 78.875%\n",
            "Epoch 7:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0503 Val_loss : 0.7072\n",
            "\tTrain_acc : 98.596% Val_acc : 79.375%\n",
            "Epoch 8:Validation accuracy did not increase\n",
            "Early stopped at epoch : 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Model"
      ],
      "metadata": {
        "id": "jhCm0jdKQroD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTM_Sentiment_Classifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM,NUM_CLASSES, LSTM_LAYERS,BIDIRECTIONAL, BATCH_SIZE, DROPOUT)\n",
        "model = model.to(DEVICE)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/22CS60R37_A8 DL/lstm_model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY9Wq4Yeu9nP",
        "outputId": "28dfd280-17d6-41e7-d135-0568f3ed7886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating our model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iDFHfUI2QvkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred_list = []\n",
        "y_test_list = []\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "    test_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "    output, val_h = model(inputs, test_h)\n",
        "    y_pred_test = torch.argmax(output, dim=1)\n",
        "    y_pred_list.extend(y_pred_test.squeeze().tolist())\n",
        "    y_test_list.extend(labels.squeeze().tolist())"
      ],
      "metadata": {
        "id": "n2clEOz0vD4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing Accuracy Report of Trained Model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U2IZa26iQ1BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "rwCawoyNvSw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report for LSTM :\\n', classification_report(y_test_list, y_pred_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa1apPgYvP8z",
        "outputId": "4f19fc95-961a-49a8-9f0c-2aae9ffe84b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for LSTM :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.78      0.81      2102\n",
            "           1       0.78      0.84      0.81      1930\n",
            "\n",
            "    accuracy                           0.81      4032\n",
            "   macro avg       0.81      0.81      0.81      4032\n",
            "weighted avg       0.81      0.81      0.81      4032\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test_list,y_pred_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G6879aFv79I",
        "outputId": "61d191b1-318d-47cc-f477-077af240dbd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1648,  454],\n",
              "       [ 315, 1615]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing for given Test.csv File\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3WoGsG5Ox3zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Tokenize(column, seq_len):\n",
        "    ##Create vocabulary of words from column\n",
        "    corpus = [word for text in tdf['tprocessed_text'] for word in text.split()]\n",
        "    count_words = Counter(corpus)\n",
        "    sorted_words = count_words.most_common()\n",
        "    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "\n",
        "    ##Tokenize the columns text using the vocabulary\n",
        "    text_int = []\n",
        "    for text in column:\n",
        "        r = [vocab_to_int[word] for word in text.split()]\n",
        "        text_int.append(r)\n",
        "    ##Add padding to tokens\n",
        "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    for i, review in enumerate(text_int):\n",
        "        if len(review) <= seq_len:\n",
        "            zeros = list(np.zeros(seq_len - len(review)))\n",
        "            new = zeros + review\n",
        "        else:\n",
        "            new = review[: seq_len]\n",
        "        features[i, :] = np.array(new)\n",
        "\n",
        "    return sorted_words, features\n",
        "\n"
      ],
      "metadata": {
        "id": "8SV_fwzQ83-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tdf['tprocessed_text']\n",
        "y = tdf['label']\n",
        "\n",
        "vocabulary, tokenized_column = Tokenize(tdf[\"tprocessed_text\"], max_len)\n",
        "\n",
        "X = tokenized_column\n",
        "y = tdf['label'].values\n",
        "\n",
        "test_data = TensorDataset(torch.from_numpy(X), torch.from_numpy(y))\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True) #\n",
        "\n",
        "model.eval()\n",
        "y_pred_list = []\n",
        "y_test_list = []\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "    test_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "    output, val_h = model(inputs, test_h)\n",
        "    y_pred_test = torch.argmax(output, dim=1)\n",
        "    y_pred_list.extend(y_pred_test.squeeze().tolist())\n",
        "    y_test_list.extend(labels.squeeze().tolist())"
      ],
      "metadata": {
        "id": "lEGGtQH5x2pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing Classification report of Test Dataset"
      ],
      "metadata": {
        "id": "ZgRgKNODRIlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report for LSTM :\\n', classification_report(y_test_list, y_pred_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px0fPuxTzXnQ",
        "outputId": "66ee5965-44fc-41e9-ffc7-a98c534cd21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for LSTM :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.90      0.92      1051\n",
            "           1       0.89      0.94      0.92       933\n",
            "\n",
            "    accuracy                           0.92      1984\n",
            "   macro avg       0.92      0.92      0.92      1984\n",
            "weighted avg       0.92      0.92      0.92      1984\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_intersection_points(train_df, val_df, new_testdf):\n",
        "  train_com_count = 0\n",
        "  val_com_count = 0\n",
        "  for sentence in train_df['text']:\n",
        "    for new_sentence in new_testdf['text']:\n",
        "      if sentence==new_sentence:\n",
        "        train_com_count += 1\n",
        "\n",
        "  for sentence in val_df['text']:\n",
        "    for new_sentence in new_testdf['text']:\n",
        "      if sentence==new_sentence:\n",
        "        val_com_count += 1\n",
        "  \n",
        "  # print(\"Intersection points for dataset used for testing and training \", modelname)\n",
        "  print(\"Common points with training dataset: \",train_com_count)\n",
        "  print(\"Common points with validation dataset: \",val_com_count)\n",
        "\n",
        "print_intersection_points(traindf, valdf, test_df)\n"
      ],
      "metadata": {
        "id": "Jn6i7ridNx3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176be1c4-3944-4556-afc9-5a7aea86591a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common points with training dataset:  166\n",
            "Common points with validation dataset:  56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWQySlOJ-Rqj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}