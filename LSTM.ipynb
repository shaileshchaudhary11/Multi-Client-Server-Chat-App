{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INSTRUCTION TO RUN THE CODE:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Training and Testing**\n",
        "\n",
        "\n",
        "\n",
        "*   **Loading Dataset** : Load the dataset for training and give path of the dataset at 'Data Processing block' for reading the dataset.\n",
        "*   **Testing Dataset** : For testing yor csv file you have to load your test_dataset.csv file and provide its path to the block 'preprocessing of test Dataset'.\n",
        "\n",
        "\n",
        "*   For removing stopword you have to upload one extra file final_stopwords.tx and provide its correct path\n",
        "\n",
        "\n",
        "\n",
        "2.   **Loading trained Model and Test:**\n",
        "\n",
        "\n",
        "*   You can test your test csv by just loading the already saved trained model lstm_model.pth that reduce training time\n"
      ],
      "metadata": {
        "id": "tuyF8znf6JT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnZ5odyBPAPF",
        "outputId": "f163ac01-cd46-4c0e-a4c5-6b31e2941115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2CqJ7x8f7zl"
      },
      "source": [
        "# Installing Neccesary library"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "5k-9ngYrx-cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "print(locale.getdefaultlocale())\n",
        "print(locale.getpreferredencoding())"
      ],
      "metadata": {
        "id": "J2KbnRZYyIpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c20c87-abee-4da6-c536-bc890ff65bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('en_US', 'UTF-8')\n",
            "UTF-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJLIGSlPDk_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad275db-f74f-4c17-a03c-f2a0a010f449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.9/dist-packages (0.15.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (0.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata==0.6.0->torchtext) (1.26.15)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (16.0.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchtext) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp39-cp39-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp39-cp39-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext==0.10.0) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.10.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.10.0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (3.4)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.1\n",
            "    Uninstalling torchtext-0.15.1:\n",
            "      Successfully uninstalled torchtext-0.15.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.9.0 torchtext-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for Pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for Pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for Pytorch\n",
            "Failed to build Pytorch\n",
            "Installing collected packages: Pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mRunning setup.py install for Pytorch\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Running setup.py install for Pytorch ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m Encountered error while trying to install package.\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m Pytorch\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=352202fd851007625753215f760baf3d252985bf629ea0020aa34e1e570368bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/b8/0f/f580817231cbf59f6ade9fd132ff60ada1de9f7dc85521f857\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.22.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext\n",
        "!pip install torchtext==0.10.0\n",
        "!pip install Pytorch\n",
        "!pip install emoji\n",
        "!pip install nltk\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D06f8yBbgHu1"
      },
      "source": [
        "# Import require Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyh1VNNOgR7J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "import collections\n",
        "from collections import Counter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jZPOD2ghRh1"
      },
      "source": [
        "# Trainig Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1yzpxpZqgc1o",
        "outputId": "de1f6b55-2eaf-417c-8f93-2454272f98af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                       text\n",
              "0      0              ‡§≠‡•Ä‡§°‡§º ‡§Æ‡•á‡§Ç  ‡§¨‡§π‡•Å‡§§  ‡§π‡§¨‡•ç‡§∏‡•Ä ‡§Æ‡§ø‡§≤‡•á‡§Ç‡§ó‡•á\n",
              "1      0  ‡§∏‡§æ‡§≤‡•á ‡§¨‡•á‡§µ‡§ï‡•Ç‡§´ ‡§Ö‡§™‡§®‡•Ä ‡§Æ‡§æ‡§Ç ‡§Æ‡§ï‡•ç‡§ñ‡§ø‡§Ø‡§æ‡§Ç  ‡§§‡•ã ‡§π‡§ü‡§æ ‡§¶‡•á‡§Ç\n",
              "2      0           ‡§¨‡•Å‡§∞ ‡§¶‡•á‡§¶‡•ã ‡§§‡•ã ‡§Æ‡•Å‡§π ‡§Æ‡•á‡§Ç ‡§≤‡§Ç‡§° ‡§≤‡•á ‡§≤‡•ã ‡§§‡•ã\n",
              "3      0       ‡§ï‡•Å‡§§‡•ç‡§§‡§æ ‡§µ‡§π‡§æ ‡§π‡•à ‡§ö‡§ø‡§≤‡•ç‡§≤‡§æ ‡§§‡•Ç ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§∞‡§π‡§æ ‡§π‡•à\n",
              "4      1  ‡§ö‡§æ‡§Ø ‡§®‡§π‡•Ä‡§Ç ‡§™‡•Ä‡§§‡§æ ‡§π‡•Ç‡§Ç ‡§Æ‡•à‡§Ç ‡§á‡§∏‡•Ä ‡§ï‡•ã ‡§õ‡•ã‡§°‡§º ‡§¶‡§ø‡§Ø‡§æ ok"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c82eef7c-4f2e-40a5-9eaa-ea0339587641\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>‡§≠‡•Ä‡§°‡§º ‡§Æ‡•á‡§Ç  ‡§¨‡§π‡•Å‡§§  ‡§π‡§¨‡•ç‡§∏‡•Ä ‡§Æ‡§ø‡§≤‡•á‡§Ç‡§ó‡•á</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>‡§∏‡§æ‡§≤‡•á ‡§¨‡•á‡§µ‡§ï‡•Ç‡§´ ‡§Ö‡§™‡§®‡•Ä ‡§Æ‡§æ‡§Ç ‡§Æ‡§ï‡•ç‡§ñ‡§ø‡§Ø‡§æ‡§Ç  ‡§§‡•ã ‡§π‡§ü‡§æ ‡§¶‡•á‡§Ç</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>‡§¨‡•Å‡§∞ ‡§¶‡•á‡§¶‡•ã ‡§§‡•ã ‡§Æ‡•Å‡§π ‡§Æ‡•á‡§Ç ‡§≤‡§Ç‡§° ‡§≤‡•á ‡§≤‡•ã ‡§§‡•ã</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>‡§ï‡•Å‡§§‡•ç‡§§‡§æ ‡§µ‡§π‡§æ ‡§π‡•à ‡§ö‡§ø‡§≤‡•ç‡§≤‡§æ ‡§§‡•Ç ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§∞‡§π‡§æ ‡§π‡•à</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>‡§ö‡§æ‡§Ø ‡§®‡§π‡•Ä‡§Ç ‡§™‡•Ä‡§§‡§æ ‡§π‡•Ç‡§Ç ‡§Æ‡•à‡§Ç ‡§á‡§∏‡•Ä ‡§ï‡•ã ‡§õ‡•ã‡§°‡§º ‡§¶‡§ø‡§Ø‡§æ ok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c82eef7c-4f2e-40a5-9eaa-ea0339587641')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c82eef7c-4f2e-40a5-9eaa-ea0339587641 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c82eef7c-4f2e-40a5-9eaa-ea0339587641');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Loading the dataset\n",
        "full_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/22CS60R37_A8 DL/hindi_train_val.csv')\n",
        "# df = full_df[[\"text\"]]\n",
        "df = full_df\n",
        "# df[\"text\"] = df[\"text\"].astype(str)\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pSmoyowhxgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988dfdb4-570d-409f-cc16-8b67ba0b5e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indic_transliteration\n",
            "  Downloading indic_transliteration-2.3.44-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting indicnlp\n",
            "  Downloading indicnlp-0.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.91-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting indic\n",
            "  Downloading indic-0.1.2.tar.gz (6.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from indic_transliteration) (2022.10.31)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.9/dist-packages (from indic_transliteration) (0.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from indic_transliteration) (0.10.2)\n",
            "Collecting backports.functools-lru-cache\n",
            "  Downloading backports.functools_lru_cache-1.6.4-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting roman\n",
            "  Downloading roman-4.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.2.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from indic-nlp-library) (1.5.3)\n",
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from indic-nlp-library) (1.22.4)\n",
            "Collecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: matplotlib>=1.3 in /usr/local/lib/python3.9/dist-packages (from indic) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.13 in /usr/local/lib/python3.9/dist-packages (from indic) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.13 in /usr/local/lib/python3.9/dist-packages (from indic) (1.10.1)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3->indic) (8.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->indic-nlp-library) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.13->indic) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.13->indic) (3.1.0)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from sphinx-argparse->indic-nlp-library) (3.5.4)\n",
            "Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.9/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.16)\n",
            "Collecting sphinxcontrib-jquery!=3.0.0,>=2.0.0\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer->indic_transliteration) (8.1.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=1.3->indic) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3->indic) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (67.6.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.14.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.27.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2022.12.7)\n",
            "Building wheels for collected packages: indic\n",
            "  Building wheel for indic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for indic: filename=indic-0.1.2-py3-none-any.whl size=10089 sha256=77d6979e12d24ad52dd8075948f02b1eeba5f4cac197a3dfad7dc8622c7164e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/46/ae/5111371e0c7d7160c689f9f6cee321acd45a4e32d4c419dd4a\n",
            "Successfully built indic\n",
            "Installing collected packages: morfessor, indicnlp, roman, backports.functools-lru-cache, indic_transliteration, sphinxcontrib-jquery, sphinx-argparse, indic, sphinx-rtd-theme, indic-nlp-library\n",
            "Successfully installed backports.functools-lru-cache-1.6.4 indic-0.1.2 indic-nlp-library-0.91 indic_transliteration-2.3.44 indicnlp-0.0.1 morfessor-2.0.6 roman-4.0 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.2.0 sphinxcontrib-jquery-4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install indic_transliteration indicnlp indic-nlp-library indic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vne2RApogtH6"
      },
      "outputs": [],
      "source": [
        "from indicnlp.tokenize import indic_tokenize\n",
        "def tokenization(indic_string):\n",
        "    tokens = []\n",
        "    for t in indic_tokenize.trivial_tokenize(indic_string):\n",
        "        tokens.append(t)\n",
        "    return tokens\n",
        "df['text'] = df['text'].apply(lambda x: tokenization(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxNJ0j70g0QN"
      },
      "outputs": [],
      "source": [
        "# stopword list\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/22CS60R37_A8 DL/final_stopwords.txt', 'r', encoding=\"utf8\") as file:\n",
        "    content = file.readlines()\n",
        "\n",
        "stopwords_hi = [line.strip() for line in content]\n",
        "\n",
        "# stopwords_hi = ['‡§§‡•Å‡§Æ','‡§Æ‡•á‡§∞‡•Ä','‡§Æ‡•Å‡§ù‡•á','‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø','‡§π‡§Æ','‡§™‡•ç‡§∞‡§§‡§ø','‡§Ö‡§¨‡§ï‡•Ä','‡§Ü‡§ó‡•á','‡§Æ‡§æ‡§®‡§®‡•Ä‡§Ø','‡§∂‡§π‡§∞','‡§¨‡§§‡§æ‡§è‡§Ç','‡§ï‡•å‡§®‡§∏‡•Ä','‡§ï‡•ç‡§≤‡§ø‡§ï','‡§ï‡§ø‡§∏‡§ï‡•Ä','‡§¨‡•ú‡•á','‡§Æ‡•à‡§Ç','and','‡§∞‡§π‡•Ä','‡§Ü‡§ú','‡§≤‡•á‡§Ç','‡§Ü‡§™‡§ï‡•á','‡§Æ‡§ø‡§≤‡§ï‡§∞','‡§∏‡§¨','‡§Æ‡•á‡§∞‡•á','‡§ú‡•Ä','‡§∂‡•ç‡§∞‡•Ä','‡§µ‡•à‡§∏‡§æ','‡§Ü‡§™‡§ï‡§æ','‡§Ö‡§Ç‡§¶‡§∞', '‡§Ö‡§§', '‡§Ö‡§™‡§®‡§æ', '‡§Ö‡§™‡§®‡•Ä', '‡§Ö‡§™‡§®‡•á', '‡§Ö‡§≠‡•Ä', '‡§Ü‡§¶‡§ø', '‡§Ü‡§™', '‡§á‡§§‡•ç‡§Ø‡§æ‡§¶‡§ø', '‡§á‡§®', '‡§á‡§®‡§ï‡§æ', '‡§á‡§®‡•ç‡§π‡•Ä‡§Ç', '‡§á‡§®‡•ç‡§π‡•á‡§Ç', '‡§á‡§®‡•ç‡§π‡•ã‡§Ç', '‡§á‡§∏', '‡§á‡§∏‡§ï‡§æ', '‡§á‡§∏‡§ï‡•Ä', '‡§á‡§∏‡§ï‡•á', '‡§á‡§∏‡§Æ‡•á‡§Ç', '‡§á‡§∏‡•Ä', '‡§á‡§∏‡•á', '‡§â‡§®', '‡§â‡§®‡§ï‡§æ', '‡§â‡§®‡§ï‡•Ä', '‡§â‡§®‡§ï‡•á', '‡§â‡§®‡§ï‡•ã', '‡§â‡§®‡•ç‡§π‡•Ä‡§Ç', '‡§â‡§®‡•ç‡§π‡•á‡§Ç', '‡§â‡§®‡•ç‡§π‡•ã‡§Ç', '‡§â‡§∏', '‡§â‡§∏‡§ï‡•á', '‡§â‡§∏‡•Ä', '‡§â‡§∏‡•á', '‡§è‡§ï', '‡§è‡§µ‡§Ç', '‡§è‡§∏', '‡§ê‡§∏‡•á', '‡§î‡§∞', '‡§ï‡§à', '‡§ï‡§∞','‡§ï‡§∞‡§§‡§æ', '‡§ï‡§∞‡§§‡•á', '‡§ï‡§∞‡§®‡§æ', '‡§ï‡§∞‡§®‡•á', '‡§ï‡§∞‡•á‡§Ç', '‡§ï‡§π‡§§‡•á', '‡§ï‡§π‡§æ', '‡§ï‡§æ', '‡§ï‡§æ‡•û‡•Ä', '‡§ï‡§ø', '‡§ï‡§ø‡§§‡§®‡§æ', '‡§ï‡§ø‡§®‡•ç‡§π‡•á‡§Ç', '‡§ï‡§ø‡§®‡•ç‡§π‡•ã‡§Ç', '‡§ï‡§ø‡§Ø‡§æ', '‡§ï‡§ø‡§∞', '‡§ï‡§ø‡§∏', '‡§ï‡§ø‡§∏‡•Ä', '‡§ï‡§ø‡§∏‡•á', '‡§ï‡•Ä', '‡§ï‡•Å‡§õ', '‡§ï‡•Å‡§≤', '‡§ï‡•á', '‡§ï‡•ã', '‡§ï‡•ã‡§à', '‡§ï‡•å‡§®', '‡§ï‡•å‡§®‡§∏‡§æ', '‡§ó‡§Ø‡§æ', '‡§ò‡§∞', '‡§ú‡§¨', '‡§ú‡§π‡§æ‡§Å', '‡§ú‡§æ', '‡§ú‡§ø‡§§‡§®‡§æ', '‡§ú‡§ø‡§®', '‡§ú‡§ø‡§®‡•ç‡§π‡•á‡§Ç', '‡§ú‡§ø‡§®‡•ç‡§π‡•ã‡§Ç', '‡§ú‡§ø‡§∏', '‡§ú‡§ø‡§∏‡•á', '‡§ú‡•Ä‡§ß‡§∞', '‡§ú‡•à‡§∏‡§æ', '‡§ú‡•à‡§∏‡•á', '‡§ú‡•ã', '‡§§‡§ï', '‡§§‡§¨', '‡§§‡§∞‡§π', '‡§§‡§ø‡§®', '‡§§‡§ø‡§®‡•ç‡§π‡•á‡§Ç', '‡§§‡§ø‡§®‡•ç‡§π‡•ã‡§Ç', '‡§§‡§ø‡§∏', '‡§§‡§ø‡§∏‡•á', '‡§§‡•ã', '‡§•‡§æ', '‡§•‡•Ä', '‡§•‡•á', '‡§¶‡§¨‡§æ‡§∞‡§æ', '‡§¶‡§ø‡§Ø‡§æ', '‡§¶‡•Å‡§∏‡§∞‡§æ', '‡§¶‡•Ç‡§∏‡§∞‡•á', '‡§¶‡•ã', '‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ', '‡§®', '‡§®‡§π‡•Ä‡§Ç', '‡§®‡§æ', '‡§®‡§ø‡§π‡§æ‡§Ø‡§§', '‡§®‡•Ä‡§ö‡•á', '‡§®‡•á', '‡§™‡§∞', '‡§™‡§∞', '‡§™‡§π‡§≤‡•á', '‡§™‡•Ç‡§∞‡§æ', '‡§™‡•á', '‡§´‡§ø‡§∞', '‡§¨‡§®‡•Ä', '‡§¨‡§π‡•Ä', '‡§¨‡§π‡•Å‡§§', '‡§¨‡§æ‡§¶', '‡§¨‡§æ‡§≤‡§æ', '‡§¨‡§ø‡§≤‡§ï‡•Å‡§≤', '‡§≠‡•Ä', '‡§≠‡•Ä‡§§‡§∞', '‡§Æ‡§ó‡§∞', '‡§Æ‡§æ‡§®‡•ã', '‡§Æ‡•á', '‡§Æ‡•á‡§Ç', '‡§Ø‡§¶‡§ø', '‡§Ø‡§π', '‡§Ø‡§π‡§æ‡§Å', '‡§Ø‡§π‡•Ä', '‡§Ø‡§æ', '‡§Ø‡§ø‡§π', '‡§Ø‡•á', '‡§∞‡§ñ‡•á‡§Ç', '‡§∞‡§π‡§æ', '‡§∞‡§π‡•á', '‡§±‡•ç‡§µ‡§æ‡§∏‡§æ', '‡§≤‡§ø‡§è', '‡§≤‡§ø‡§Ø‡•á', '‡§≤‡•á‡§ï‡§ø‡§®', '‡§µ', '‡§µ‡§∞‡•ç‡§ó', '‡§µ‡§π', '‡§µ‡§π', '‡§µ‡§π‡§æ‡§Å', '‡§µ‡§π‡•Ä‡§Ç', '‡§µ‡§æ‡§≤‡•á', '‡§µ‡•Å‡§π', '‡§µ‡•á', '‡§µ‡•ö‡•à‡§∞‡§π', '‡§∏‡§Ç‡§ó', '‡§∏‡§ï‡§§‡§æ', '‡§∏‡§ï‡§§‡•á', '‡§∏‡§¨‡§∏‡•á', '‡§∏‡§≠‡•Ä', '‡§∏‡§æ‡§•', '‡§∏‡§æ‡§¨‡•Å‡§§', '‡§∏‡§æ‡§≠', '‡§∏‡§æ‡§∞‡§æ', '‡§∏‡•á', '‡§∏‡•ã', '‡§π‡•Ä', '‡§π‡•Å‡§Ü', '‡§π‡•Å‡§à', '‡§π‡•Å‡§è', '‡§π‡•à', '‡§π‡•à‡§Ç', '‡§π‡•ã', '‡§π‡•ã‡§§‡§æ', '‡§π‡•ã‡§§‡•Ä', '‡§π‡•ã‡§§‡•á', '‡§π‡•ã‡§®‡§æ', '‡§π‡•ã‡§®‡•á', '‡§Ö‡§™‡§®‡§ø', '‡§ú‡•á‡§∏‡•á', '‡§π‡•ã‡§§‡§ø', '‡§∏‡§≠‡§ø', '‡§§‡§ø‡§Ç‡§π‡•ã‡§Ç', '‡§á‡§Ç‡§π‡•ã‡§Ç', '‡§¶‡§µ‡§æ‡§∞‡§æ', '‡§á‡§∏‡§ø', '‡§ï‡§ø‡§Ç‡§π‡•á‡§Ç', '‡§•‡§ø', '‡§â‡§Ç‡§π‡•ã‡§Ç', '‡§ì‡§∞', '‡§ú‡§ø‡§Ç‡§π‡•á‡§Ç', '‡§µ‡§π‡§ø‡§Ç', '‡§Ö‡§≠‡§ø', '‡§¨‡§®‡§ø', '‡§π‡§ø', '‡§â‡§Ç‡§π‡§ø‡§Ç', '‡§â‡§Ç‡§π‡•á‡§Ç', '‡§π‡•á‡§Ç', '‡§µ‡§ó‡•á‡§∞‡§π', '‡§è‡§∏‡•á', '‡§∞‡§µ‡§æ‡§∏‡§æ', '‡§ï‡•ã‡§®', '‡§®‡§ø‡§ö‡•á', '‡§ï‡§æ‡§´‡§ø', '‡§â‡§∏‡§ø', '‡§™‡•Å‡§∞‡§æ', '‡§≠‡§ø‡§§‡§∞', '‡§π‡•á', '‡§¨‡§π‡§ø', '‡§µ‡§π‡§æ‡§Ç', '‡§ï‡•ã‡§á', '‡§Ø‡§π‡§æ‡§Ç', '‡§ú‡§ø‡§Ç‡§π‡•ã‡§Ç', '‡§§‡§ø‡§Ç‡§π‡•á‡§Ç', '‡§ï‡§ø‡§∏‡§ø', '‡§ï‡§á', '‡§Ø‡§π‡§ø', '‡§á‡§Ç‡§π‡§ø‡§Ç', '‡§ú‡§ø‡§ß‡§∞', '‡§á‡§Ç‡§π‡•á‡§Ç', '‡§Ö‡§¶‡§ø', '‡§á‡§§‡§Ø‡§æ‡§¶‡§ø', '‡§π‡•Å‡§á', '‡§ï‡•ã‡§®‡§∏‡§æ', '‡§á‡§∏‡§ï‡§ø', '‡§¶‡•Å‡§∏‡§∞‡•á', '‡§ú‡§π‡§æ‡§Ç', '‡§Ö‡§™', '‡§ï‡§ø‡§Ç‡§π‡•ã‡§Ç', '‡§â‡§®‡§ï‡§ø', '‡§≠‡§ø', '‡§µ‡§∞‡§ó', '‡§π‡•Å‡§Ö', '‡§ú‡•á‡§∏‡§æ', '‡§®‡§π‡§ø‡§Ç']\n",
        "stopwords_en = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "# punctuations = ['nn','n', '‡•§','/', '`', '+', '\\', '\"', '?', '‚ñÅ(', '$', '@', '[', '_', \"'\", '!', ',', ':', '^', '|', ']', '=', '%', '&', '.', ')', '(', '#', '*', '', ';', '-', '}','|','\"']\n",
        "\n",
        "# punctuations = ['(', ')', '?', ':', ';', ',', '.', '!', '/', '\"', \"'\"]\n",
        "\n",
        "punctuations = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"-\", \"‚Äî\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"/\", \"\\\\\", \"|\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"*\", \"+\", \"=\", \"<\", \">\", \"_\", \"~\", \"`\", \"'\", \"\\\"\", \"¬´\", \"¬ª\", \"‚Äú\", \"‚Äù\", \"‚Äò\", \"‚Äô\", \"‚Äπ\", \"‚Ä∫\", \"‚Äû\", \"‚Äü\", \"‚Äõ\", \"‚Äü\", \"‚Äò\", \"‚Äô\", \"‚Äö\", \"‚Äõ\", \"‚Äü\", \"‚Äπ\", \"‚Ä∫\", \"„Äà\", \"„Äâ\", \"„Ää\", \"„Äã\", \"„Äå\", \"„Äç\", \"„Äé\", \"„Äè\", \"„Äê\", \"„Äë\"]\n",
        "\n",
        "\n",
        "\n",
        "to_be_removed = stopwords_hi + punctuations + stopwords_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Sxm03trTg6ts",
        "outputId": "c9e91832-fd94-48fd-b867-24a1dfdc9617"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                               text\n",
              "20173      0                               [‡§†‡•ã‡§ï, ‡§§‡•Ç, ‡§Ö‡§ö‡•ç‡§õ‡§æ, ‡§®‡§æ]\n",
              "20174      1  [üí•üí•üí•, ‡§ó‡•Å‡§°, ‡§®‡§æ‡§á‡§ü, ‡§ú‡•Äüí•üí•üí•üí•üôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇ...\n",
              "20175      0                                   [‡§§‡•á‡§∞‡•Ä, ‡§Æ‡§æ‡§Å, ‡§ï‡§∏‡§Æ]\n",
              "20176      1  [‡§ú‡•Ä‡§µ‡§®, ‡§ú‡•Ä‡§®‡•á, ‡§ï‡•á, ‡§§‡§∞‡•Ä‡§ï‡•á, ‡§Æ‡§æ‡§Ø‡§®‡•á, ‡§ï‡•á, ‡§ö‡§Æ‡§§‡•ç‡§ï‡§æ‡§∞, ‡§®‡§π...\n",
              "20177      1                               [‡§§‡•Ä‡§∏‡§∞‡§æ, ‡§®‡§æ‡§Æ‡•ç, ‡§ï‡§≤‡•ç‡§≤‡•Ç]\n",
              "20178      0                         [‡§õ‡•ã‡§ü‡•á, ‡§ï‡•ç‡§Ø‡•Å, ‡§™‡§π‡§®‡§§‡•á, ‡§ú‡§∞‡•Ç‡§∞‡§§]\n",
              "20179      1                  [‡§ï‡•à‡§∏‡•Ä, ‡§∏‡•ã‡§®‡§æ, ‡§π‡§Æ‡§∏‡•á, ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä, ‡§ï‡§∞‡•ã‡§ó‡•Ä]\n",
              "20180      1                       [‡§™‡§§‡§æ, ‡§ö‡§≤‡§§‡§æ, ‡§ö‡•Å‡§®‡§æ‡§µ, ‡§Ü, ‡§π‡•àüôÑüôÑüôÑ]\n",
              "20181      1                 [‡§ñ‡•á‡§§, ‡§ú‡•ã‡§§‡•á, ‡§ï‡§ø‡§∏‡§æ‡§®, ‡§≠‡•à‡§Ç‡§∏, ‡§ï‡•á, ‡§∏‡§æ‡§•‡•ã]\n",
              "20182      0  [‡§ï‡§æ‡§∂, ‡§Ü‡§ó‡§∞, ‡§á‡§§‡§®‡§æ, ‡§¶‡§ø‡§Æ‡§æ‡§ó, ‡§™‡§¢‡§æ‡§à, ‡§≤‡§ó‡§æ‡§Ø‡•á‡§Ç, ‡§∂‡§æ‡§Ø‡§¶, ‡§ú‡§æ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30568c85-1f20-4eff-8726-6f3f78e30962\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20173</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§†‡•ã‡§ï, ‡§§‡•Ç, ‡§Ö‡§ö‡•ç‡§õ‡§æ, ‡§®‡§æ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20174</th>\n",
              "      <td>1</td>\n",
              "      <td>[üí•üí•üí•, ‡§ó‡•Å‡§°, ‡§®‡§æ‡§á‡§ü, ‡§ú‡•Äüí•üí•üí•üí•üôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20175</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§§‡•á‡§∞‡•Ä, ‡§Æ‡§æ‡§Å, ‡§ï‡§∏‡§Æ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20176</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§ú‡•Ä‡§µ‡§®, ‡§ú‡•Ä‡§®‡•á, ‡§ï‡•á, ‡§§‡§∞‡•Ä‡§ï‡•á, ‡§Æ‡§æ‡§Ø‡§®‡•á, ‡§ï‡•á, ‡§ö‡§Æ‡§§‡•ç‡§ï‡§æ‡§∞, ‡§®‡§π...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20177</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§§‡•Ä‡§∏‡§∞‡§æ, ‡§®‡§æ‡§Æ‡•ç, ‡§ï‡§≤‡•ç‡§≤‡•Ç]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20178</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§õ‡•ã‡§ü‡•á, ‡§ï‡•ç‡§Ø‡•Å, ‡§™‡§π‡§®‡§§‡•á, ‡§ú‡§∞‡•Ç‡§∞‡§§]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20179</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§ï‡•à‡§∏‡•Ä, ‡§∏‡•ã‡§®‡§æ, ‡§π‡§Æ‡§∏‡•á, ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä, ‡§ï‡§∞‡•ã‡§ó‡•Ä]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20180</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§™‡§§‡§æ, ‡§ö‡§≤‡§§‡§æ, ‡§ö‡•Å‡§®‡§æ‡§µ, ‡§Ü, ‡§π‡•àüôÑüôÑüôÑ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20181</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§ñ‡•á‡§§, ‡§ú‡•ã‡§§‡•á, ‡§ï‡§ø‡§∏‡§æ‡§®, ‡§≠‡•à‡§Ç‡§∏, ‡§ï‡•á, ‡§∏‡§æ‡§•‡•ã]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20182</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§ï‡§æ‡§∂, ‡§Ü‡§ó‡§∞, ‡§á‡§§‡§®‡§æ, ‡§¶‡§ø‡§Æ‡§æ‡§ó, ‡§™‡§¢‡§æ‡§à, ‡§≤‡§ó‡§æ‡§Ø‡•á‡§Ç, ‡§∂‡§æ‡§Ø‡§¶, ‡§ú‡§æ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30568c85-1f20-4eff-8726-6f3f78e30962')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30568c85-1f20-4eff-8726-6f3f78e30962 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30568c85-1f20-4eff-8726-6f3f78e30962');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# removing all stopword\n",
        "\n",
        "for i in range(len(df)):\n",
        "    df['text'][i]=[ele for ele in df['text'][i] if ele not in (to_be_removed)]\n",
        "# count_length()\n",
        "df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "NEXayJywg_Wq",
        "outputId": "5f0a5151-6340-4c17-d50f-94857d85ae50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                               text  \\\n",
              "20173      0                               [‡§†‡•ã‡§ï, ‡§§‡•Ç, ‡§Ö‡§ö‡•ç‡§õ‡§æ, ‡§®‡§æ]   \n",
              "20174      1  [üí•üí•üí•, ‡§ó‡•Å‡§°, ‡§®‡§æ‡§á‡§ü, ‡§ú‡•Äüí•üí•üí•üí•üôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇ...   \n",
              "20175      0                                   [‡§§‡•á‡§∞‡•Ä, ‡§Æ‡§æ‡§Å, ‡§ï‡§∏‡§Æ]   \n",
              "20176      1  [‡§ú‡•Ä‡§µ‡§®, ‡§ú‡•Ä‡§®‡•á, ‡§ï‡•á, ‡§§‡§∞‡•Ä‡§ï‡•á, ‡§Æ‡§æ‡§Ø‡§®‡•á, ‡§ï‡•á, ‡§ö‡§Æ‡§§‡•ç‡§ï‡§æ‡§∞, ‡§®‡§π...   \n",
              "20177      1                               [‡§§‡•Ä‡§∏‡§∞‡§æ, ‡§®‡§æ‡§Æ‡•ç, ‡§ï‡§≤‡•ç‡§≤‡•Ç]   \n",
              "20178      0                         [‡§õ‡•ã‡§ü‡•á, ‡§ï‡•ç‡§Ø‡•Å, ‡§™‡§π‡§®‡§§‡•á, ‡§ú‡§∞‡•Ç‡§∞‡§§]   \n",
              "20179      1                  [‡§ï‡•à‡§∏‡•Ä, ‡§∏‡•ã‡§®‡§æ, ‡§π‡§Æ‡§∏‡•á, ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä, ‡§ï‡§∞‡•ã‡§ó‡•Ä]   \n",
              "20180      1                       [‡§™‡§§‡§æ, ‡§ö‡§≤‡§§‡§æ, ‡§ö‡•Å‡§®‡§æ‡§µ, ‡§Ü, ‡§π‡•àüôÑüôÑüôÑ]   \n",
              "20181      1                 [‡§ñ‡•á‡§§, ‡§ú‡•ã‡§§‡•á, ‡§ï‡§ø‡§∏‡§æ‡§®, ‡§≠‡•à‡§Ç‡§∏, ‡§ï‡•á, ‡§∏‡§æ‡§•‡•ã]   \n",
              "20182      0  [‡§ï‡§æ‡§∂, ‡§Ü‡§ó‡§∞, ‡§á‡§§‡§®‡§æ, ‡§¶‡§ø‡§Æ‡§æ‡§ó, ‡§™‡§¢‡§æ‡§à, ‡§≤‡§ó‡§æ‡§Ø‡•á‡§Ç, ‡§∂‡§æ‡§Ø‡§¶, ‡§ú‡§æ...   \n",
              "\n",
              "                                          processed_text  \n",
              "20173                                    ‡§†‡•ã‡§ï ‡§§‡•Ç ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§®‡§æ  \n",
              "20174  üí•üí•üí• ‡§ó‡•Å‡§° ‡§®‡§æ‡§á‡§ü ‡§ú‡•Äüí•üí•üí•üí•üôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇ...  \n",
              "20175                                       ‡§§‡•á‡§∞‡•Ä ‡§Æ‡§æ‡§Å ‡§ï‡§∏‡§Æ  \n",
              "20176  ‡§ú‡•Ä‡§µ‡§® ‡§ú‡•Ä‡§®‡•á ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á ‡§Æ‡§æ‡§Ø‡§®‡•á ‡§ï‡•á ‡§ö‡§Æ‡§§‡•ç‡§ï‡§æ‡§∞ ‡§®‡§π‡•Ä ‡§¶‡•Å‡§∏‡§∞‡•á ...  \n",
              "20177                                   ‡§§‡•Ä‡§∏‡§∞‡§æ ‡§®‡§æ‡§Æ‡•ç ‡§ï‡§≤‡•ç‡§≤‡•Ç  \n",
              "20178                              ‡§õ‡•ã‡§ü‡•á ‡§ï‡•ç‡§Ø‡•Å ‡§™‡§π‡§®‡§§‡•á ‡§ú‡§∞‡•Ç‡§∞‡§§  \n",
              "20179                        ‡§ï‡•à‡§∏‡•Ä ‡§∏‡•ã‡§®‡§æ ‡§π‡§Æ‡§∏‡•á ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä ‡§ï‡§∞‡•ã‡§ó‡•Ä  \n",
              "20180                             ‡§™‡§§‡§æ ‡§ö‡§≤‡§§‡§æ ‡§ö‡•Å‡§®‡§æ‡§µ ‡§Ü ‡§π‡•àüôÑüôÑüôÑ  \n",
              "20181                        ‡§ñ‡•á‡§§ ‡§ú‡•ã‡§§‡•á ‡§ï‡§ø‡§∏‡§æ‡§® ‡§≠‡•à‡§Ç‡§∏ ‡§ï‡•á ‡§∏‡§æ‡§•‡•ã  \n",
              "20182  ‡§ï‡§æ‡§∂ ‡§Ü‡§ó‡§∞ ‡§á‡§§‡§®‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§™‡§¢‡§æ‡§à ‡§≤‡§ó‡§æ‡§Ø‡•á‡§Ç ‡§∂‡§æ‡§Ø‡§¶ ‡§ú‡§æ‡§ï‡§∞ ‡§°‡•â‡§ï‡•ç‡§ü...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acf607b1-4f47-4aef-b847-5561bb344061\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20173</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§†‡•ã‡§ï, ‡§§‡•Ç, ‡§Ö‡§ö‡•ç‡§õ‡§æ, ‡§®‡§æ]</td>\n",
              "      <td>‡§†‡•ã‡§ï ‡§§‡•Ç ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§®‡§æ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20174</th>\n",
              "      <td>1</td>\n",
              "      <td>[üí•üí•üí•, ‡§ó‡•Å‡§°, ‡§®‡§æ‡§á‡§ü, ‡§ú‡•Äüí•üí•üí•üí•üôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇ...</td>\n",
              "      <td>üí•üí•üí• ‡§ó‡•Å‡§° ‡§®‡§æ‡§á‡§ü ‡§ú‡•Äüí•üí•üí•üí•üôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÇ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20175</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§§‡•á‡§∞‡•Ä, ‡§Æ‡§æ‡§Å, ‡§ï‡§∏‡§Æ]</td>\n",
              "      <td>‡§§‡•á‡§∞‡•Ä ‡§Æ‡§æ‡§Å ‡§ï‡§∏‡§Æ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20176</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§ú‡•Ä‡§µ‡§®, ‡§ú‡•Ä‡§®‡•á, ‡§ï‡•á, ‡§§‡§∞‡•Ä‡§ï‡•á, ‡§Æ‡§æ‡§Ø‡§®‡•á, ‡§ï‡•á, ‡§ö‡§Æ‡§§‡•ç‡§ï‡§æ‡§∞, ‡§®‡§π...</td>\n",
              "      <td>‡§ú‡•Ä‡§µ‡§® ‡§ú‡•Ä‡§®‡•á ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á ‡§Æ‡§æ‡§Ø‡§®‡•á ‡§ï‡•á ‡§ö‡§Æ‡§§‡•ç‡§ï‡§æ‡§∞ ‡§®‡§π‡•Ä ‡§¶‡•Å‡§∏‡§∞‡•á ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20177</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§§‡•Ä‡§∏‡§∞‡§æ, ‡§®‡§æ‡§Æ‡•ç, ‡§ï‡§≤‡•ç‡§≤‡•Ç]</td>\n",
              "      <td>‡§§‡•Ä‡§∏‡§∞‡§æ ‡§®‡§æ‡§Æ‡•ç ‡§ï‡§≤‡•ç‡§≤‡•Ç</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20178</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§õ‡•ã‡§ü‡•á, ‡§ï‡•ç‡§Ø‡•Å, ‡§™‡§π‡§®‡§§‡•á, ‡§ú‡§∞‡•Ç‡§∞‡§§]</td>\n",
              "      <td>‡§õ‡•ã‡§ü‡•á ‡§ï‡•ç‡§Ø‡•Å ‡§™‡§π‡§®‡§§‡•á ‡§ú‡§∞‡•Ç‡§∞‡§§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20179</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§ï‡•à‡§∏‡•Ä, ‡§∏‡•ã‡§®‡§æ, ‡§π‡§Æ‡§∏‡•á, ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä, ‡§ï‡§∞‡•ã‡§ó‡•Ä]</td>\n",
              "      <td>‡§ï‡•à‡§∏‡•Ä ‡§∏‡•ã‡§®‡§æ ‡§π‡§Æ‡§∏‡•á ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä ‡§ï‡§∞‡•ã‡§ó‡•Ä</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20180</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§™‡§§‡§æ, ‡§ö‡§≤‡§§‡§æ, ‡§ö‡•Å‡§®‡§æ‡§µ, ‡§Ü, ‡§π‡•àüôÑüôÑüôÑ]</td>\n",
              "      <td>‡§™‡§§‡§æ ‡§ö‡§≤‡§§‡§æ ‡§ö‡•Å‡§®‡§æ‡§µ ‡§Ü ‡§π‡•àüôÑüôÑüôÑ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20181</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§ñ‡•á‡§§, ‡§ú‡•ã‡§§‡•á, ‡§ï‡§ø‡§∏‡§æ‡§®, ‡§≠‡•à‡§Ç‡§∏, ‡§ï‡•á, ‡§∏‡§æ‡§•‡•ã]</td>\n",
              "      <td>‡§ñ‡•á‡§§ ‡§ú‡•ã‡§§‡•á ‡§ï‡§ø‡§∏‡§æ‡§® ‡§≠‡•à‡§Ç‡§∏ ‡§ï‡•á ‡§∏‡§æ‡§•‡•ã</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20182</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§ï‡§æ‡§∂, ‡§Ü‡§ó‡§∞, ‡§á‡§§‡§®‡§æ, ‡§¶‡§ø‡§Æ‡§æ‡§ó, ‡§™‡§¢‡§æ‡§à, ‡§≤‡§ó‡§æ‡§Ø‡•á‡§Ç, ‡§∂‡§æ‡§Ø‡§¶, ‡§ú‡§æ...</td>\n",
              "      <td>‡§ï‡§æ‡§∂ ‡§Ü‡§ó‡§∞ ‡§á‡§§‡§®‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§™‡§¢‡§æ‡§à ‡§≤‡§ó‡§æ‡§Ø‡•á‡§Ç ‡§∂‡§æ‡§Ø‡§¶ ‡§ú‡§æ‡§ï‡§∞ ‡§°‡•â‡§ï‡•ç‡§ü...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acf607b1-4f47-4aef-b847-5561bb344061')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acf607b1-4f47-4aef-b847-5561bb344061 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acf607b1-4f47-4aef-b847-5561bb344061');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Converting list to string \n",
        "\n",
        "# Create a new column called 'processed_text'\n",
        "df['processed_text'] = ''\n",
        "\n",
        "# Iterate over each row of the DataFrame\n",
        "for i in range(len(df)):\n",
        "    # Join the list of strings in the 'text' column with a space separator\n",
        "    text_string = ' '.join(df['text'][i])\n",
        "    # Remove the stopwords from the text string\n",
        "    text_string = ' '.join([word for word in text_string.split() if word.lower() not in to_be_removed])\n",
        "    # Update the 'processed_text' column with the processed text string\n",
        "    df.loc[i, 'processed_text'] = text_string\n",
        "\n",
        "# # Call the count_length() function (assuming it's defined somewhere)\n",
        "# count_length()\n",
        "\n",
        "df.tail(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindf, valdf = train_test_split(df,train_size=0.8)"
      ],
      "metadata": {
        "id": "NCWklakE-cuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Test Dataset"
      ],
      "metadata": {
        "id": "n5VdOMHW52-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/22CS60R37_A8 DL/hindi_test.csv')\n",
        "# df = full_df[[\"text\"]]\n",
        "tdf = test_df\n",
        "# df[\"text\"] = df[\"text\"].astype(str)\n",
        "tdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JyHN9SiP5xMt",
        "outputId": "a04f70b8-f4a5-44c7-b56a-03162d1e9cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  ‡§Æ‡•à‡§Ç ‡§Ø‡•á ‡§®‡§π‡•Ä ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§ï‡•Ä ‡§á‡§∏‡•á ‡§®‡§ø‡§ï‡§≤‡•á ‡§ï‡•à‡§∏‡•á ‡§Æ‡•à‡§Ç ‡§Ø‡•á ‡§∏‡•ã...\n",
              "1      1        ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡•á‡§Ç ‡§≠‡•Ä ‡§™‡•Ç‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§™‡§°‡§º‡§æ‡§ï‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§´‡•ã‡§°‡§æ‡§§\n",
              "2      1      ‡§ï‡•Å‡§§‡•ç‡§§‡§æ ‡§¨‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§™‡§æ‡§≤ ‡§≤‡•á‡§®‡§æ ‡§Æ‡§ó‡§∞ ‡§ó‡§≤‡§§ ‡§´‡§π‡§Æ‡•Ä ‡§ï‡§≠‡•Ä ‡§®‡§π‡•Ä‡§Ç‡•§\n",
              "3      0      ‡§§‡•á‡§∞‡•Ä ‡§ó‡§æ‡§Ç‡§° ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§Ø‡§æ‡§ú ‡§ï‡§æ‡§ü ‡§¶‡•á‡§ó‡§æ ‡§ó‡•Å‡§ú‡•ç‡§ú‡§∞ ‡§≠‡•ã‡§∏‡§°‡§º‡•Ä ‡§ï‡•á\n",
              "4      1            ‡§¨‡§Ç‡§ó‡§æ‡§≤‡•Ä ‡§∏‡§æ‡§°‡§º‡•Ä ‡§ê‡§∏‡•á ‡§®‡§π‡•Ä‡§Ç ‡§™‡§π‡§®‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à ‡§¶‡•Ä‡§¶‡•Ä"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd97f982-5e01-4f33-b2fc-68aeb5295f9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>‡§Æ‡•à‡§Ç ‡§Ø‡•á ‡§®‡§π‡•Ä ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§ï‡•Ä ‡§á‡§∏‡•á ‡§®‡§ø‡§ï‡§≤‡•á ‡§ï‡•à‡§∏‡•á ‡§Æ‡•à‡§Ç ‡§Ø‡•á ‡§∏‡•ã...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡•á‡§Ç ‡§≠‡•Ä ‡§™‡•Ç‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§™‡§°‡§º‡§æ‡§ï‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§´‡•ã‡§°‡§æ‡§§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>‡§ï‡•Å‡§§‡•ç‡§§‡§æ ‡§¨‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§™‡§æ‡§≤ ‡§≤‡•á‡§®‡§æ ‡§Æ‡§ó‡§∞ ‡§ó‡§≤‡§§ ‡§´‡§π‡§Æ‡•Ä ‡§ï‡§≠‡•Ä ‡§®‡§π‡•Ä‡§Ç‡•§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>‡§§‡•á‡§∞‡•Ä ‡§ó‡§æ‡§Ç‡§° ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§Ø‡§æ‡§ú ‡§ï‡§æ‡§ü ‡§¶‡•á‡§ó‡§æ ‡§ó‡•Å‡§ú‡•ç‡§ú‡§∞ ‡§≠‡•ã‡§∏‡§°‡§º‡•Ä ‡§ï‡•á</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>‡§¨‡§Ç‡§ó‡§æ‡§≤‡•Ä ‡§∏‡§æ‡§°‡§º‡•Ä ‡§ê‡§∏‡•á ‡§®‡§π‡•Ä‡§Ç ‡§™‡§π‡§®‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à ‡§¶‡•Ä‡§¶‡•Ä</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd97f982-5e01-4f33-b2fc-68aeb5295f9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd97f982-5e01-4f33-b2fc-68aeb5295f9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd97f982-5e01-4f33-b2fc-68aeb5295f9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from indicnlp.tokenize import indic_tokenize\n",
        "def tokenization(indic_string):\n",
        "    tokens = []\n",
        "    for t in indic_tokenize.trivial_tokenize(indic_string):\n",
        "        tokens.append(t)\n",
        "    return tokens\n",
        "tdf['text'] = tdf['text'].apply(lambda x: tokenization(x))\n",
        "\n",
        "# removing all stopword\n",
        "\n",
        "for i in range(len(tdf)):\n",
        "    tdf['text'][i]=[ele for ele in tdf['text'][i] if ele not in (to_be_removed)]\n",
        "# count_length()\n",
        "# tdf.tail(10)\n",
        "\n",
        "# Converting list to string \n",
        "\n",
        "# Create a new column called 'processed_text'\n",
        "tdf['tprocessed_text'] = ''\n",
        "\n",
        "# Iterate over each row of the DataFrame\n",
        "for i in range(len(tdf)):\n",
        "    # Join the list of strings in the 'text' column with a space separator\n",
        "    text_string = ' '.join(tdf['text'][i])\n",
        "    # Remove the stopwords from the text string\n",
        "    text_string = ' '.join([word for word in text_string.split() if word.lower() not in to_be_removed])\n",
        "    # Update the 'processed_text' column with the processed text string\n",
        "    tdf.loc[i, 'tprocessed_text'] = text_string\n",
        "\n",
        "# Call the count_length() function (assuming it's defined somewhere)\n",
        "# count_length()\n",
        "\n",
        "tdf.tail(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EpOQK8Zl58sq",
        "outputId": "87acf022-a4b4-4242-8ba5-68369fc03687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text  \\\n",
              "6718      0                  [‡§ö‡•Ç‡§§‡§ø‡§Ø‡•ã, ‡§ï‡§Æ‡•Ä, ‡§®‡§π‡•Ä‡§Ç, ‡§¨‡§¢‡§º‡§ï‡§∞, ‡§ö‡•Å‡§§‡§ø‡§Ø]   \n",
              "6719      0  [‡§™‡•ç‡§Ø‡§æ‡§∞‚ù§, ‡§µ‡•ç‡§Ø‡§æ‡§∞, üíî‡§∏‡§æ‡§≤‡§æ, ‡§∏‡§¨, ‡§ß‡•ã‡§ñ‡§æ, üò°‡§π‡•à, ‡§¨‡§ø‡§®‡§æ, ‡§ú‡§ø...   \n",
              "6720      0           [‡§®‡§Ç‡§ó‡•Ä, ‡§π‡•ã‡§ï‡§∞, ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã, ‡§¨‡§®‡§æ‡§ì, ‡§Ö‡§ö‡•ç‡§õ‡•Ä, ‡§≤‡§ó‡•ã‡§ó‡•Ä]   \n",
              "6721      0  [‡§∏‡§π‡•Ä, ‡§§‡§∞‡•Ä‡§ï‡•á, ‡§ï‡§™‡§°‡§º‡•á, ‡§¶‡§ø‡§ñ‡§æ‡§®‡•á, ‡§ï‡•á, ‡§Æ‡•á‡§∞‡•á, ‡§™‡§æ‡§∏, ‡§ï‡§™‡§°‡§º‡§æ]   \n",
              "6722      1  [‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä, ‡§¶‡•á‡§®, ‡§Æ‡§Ç‡§¶‡§ø‡§∞, ‡§∏‡§¨, ‡§Æ‡§Ç‡§¶‡§ø‡§∞, ‡§∞‡•Å‡§ï‡§µ‡§æ‡§®‡•á, ‡§ï‡§∏‡§∞, ...   \n",
              "6723      0                [‡§Ü‡§∞‡•á, ‡§™‡§æ‡§ó‡§≤, ‡§≤‡§µ‡§°‡•á, ‡§∏‡§Æ‡§ú, ‡§Ü‡§Ø‡•á, ‡§µ‡•ã, ‡§®‡§æ]   \n",
              "6724      0  [‡§∂‡•á‡§∞, ‡§®‡•õ‡§∞, ‡§Ö‡§Ç‡§¶‡§æ‡•õ, ‡•§, ‡§ï‡§Æ‡§ú‡•ã‡§∞‡•Ä, ‡§Æ‡§§, ‡§∏‡§Æ‡§ù, ‡§≤‡•á‡§®‡§æ, ‡§§‡•Å...   \n",
              "6725      0                        [‡§≤‡§æ‡§≤, ‡§ö‡§°‡•ç‡§°‡•Ä, ‡§ï‡•á, ‡§≤‡§æ‡§≤, ‡§π‡•ã‡§ó‡§æ]   \n",
              "6726      1                                                 []   \n",
              "6727      0  [‡§™‡•ã‡§∞‡•Ä‡§ö‡•ç‡§Ø‡§æ, ‡§´‡•ã‡§ü‡•ã, ‡§ï‡§æ‡§Ø, ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú‡§æ‡§Ç‡§ö‡•á, ‡§®‡§æ‡§ü‡§ï, ‡§∞‡•á, ‡§Æ‡§æ...   \n",
              "\n",
              "                                        tprocessed_text  \n",
              "6718                        ‡§ö‡•Ç‡§§‡§ø‡§Ø‡•ã ‡§ï‡§Æ‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§¢‡§º‡§ï‡§∞ ‡§ö‡•Å‡§§‡§ø‡§Ø  \n",
              "6719  ‡§™‡•ç‡§Ø‡§æ‡§∞‚ù§ ‡§µ‡•ç‡§Ø‡§æ‡§∞ üíî‡§∏‡§æ‡§≤‡§æ ‡§∏‡§¨ ‡§ß‡•ã‡§ñ‡§æ üò°‡§π‡•à ‡§¨‡§ø‡§®‡§æ ‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä üåé‡§ú‡•Ä...  \n",
              "6720                  ‡§®‡§Ç‡§ó‡•Ä ‡§π‡•ã‡§ï‡§∞ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§¨‡§®‡§æ‡§ì ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§≤‡§ó‡•ã‡§ó‡•Ä  \n",
              "6721           ‡§∏‡§π‡•Ä ‡§§‡§∞‡•Ä‡§ï‡•á ‡§ï‡§™‡§°‡§º‡•á ‡§¶‡§ø‡§ñ‡§æ‡§®‡•á ‡§ï‡•á ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ï‡§™‡§°‡§º‡§æ  \n",
              "6722  ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•á‡§® ‡§Æ‡§Ç‡§¶‡§ø‡§∞ ‡§∏‡§¨ ‡§Æ‡§Ç‡§¶‡§ø‡§∞ ‡§∞‡•Å‡§ï‡§µ‡§æ‡§®‡•á ‡§ï‡§∏‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§õ‡•ã‡§°...  \n",
              "6723                        ‡§Ü‡§∞‡•á ‡§™‡§æ‡§ó‡§≤ ‡§≤‡§µ‡§°‡•á ‡§∏‡§Æ‡§ú ‡§Ü‡§Ø‡•á ‡§µ‡•ã ‡§®‡§æ  \n",
              "6724  ‡§∂‡•á‡§∞ ‡§®‡•õ‡§∞ ‡§Ö‡§Ç‡§¶‡§æ‡•õ ‡•§ ‡§ï‡§Æ‡§ú‡•ã‡§∞‡•Ä ‡§Æ‡§§ ‡§∏‡§Æ‡§ù ‡§≤‡•á‡§®‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§ï‡•å...  \n",
              "6725                              ‡§≤‡§æ‡§≤ ‡§ö‡§°‡•ç‡§°‡•Ä ‡§ï‡•á ‡§≤‡§æ‡§≤ ‡§π‡•ã‡§ó‡§æ  \n",
              "6726                                                     \n",
              "6727       ‡§™‡•ã‡§∞‡•Ä‡§ö‡•ç‡§Ø‡§æ ‡§´‡•ã‡§ü‡•ã ‡§ï‡§æ‡§Ø ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§ü‡§ï ‡§∞‡•á ‡§Æ‡§æ‡§¶‡§∞‡§ö‡•ã‡§§  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14172312-0c28-4478-9581-4663eca0c5f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>tprocessed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6718</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§ö‡•Ç‡§§‡§ø‡§Ø‡•ã, ‡§ï‡§Æ‡•Ä, ‡§®‡§π‡•Ä‡§Ç, ‡§¨‡§¢‡§º‡§ï‡§∞, ‡§ö‡•Å‡§§‡§ø‡§Ø]</td>\n",
              "      <td>‡§ö‡•Ç‡§§‡§ø‡§Ø‡•ã ‡§ï‡§Æ‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§¢‡§º‡§ï‡§∞ ‡§ö‡•Å‡§§‡§ø‡§Ø</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6719</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§™‡•ç‡§Ø‡§æ‡§∞‚ù§, ‡§µ‡•ç‡§Ø‡§æ‡§∞, üíî‡§∏‡§æ‡§≤‡§æ, ‡§∏‡§¨, ‡§ß‡•ã‡§ñ‡§æ, üò°‡§π‡•à, ‡§¨‡§ø‡§®‡§æ, ‡§ú‡§ø...</td>\n",
              "      <td>‡§™‡•ç‡§Ø‡§æ‡§∞‚ù§ ‡§µ‡•ç‡§Ø‡§æ‡§∞ üíî‡§∏‡§æ‡§≤‡§æ ‡§∏‡§¨ ‡§ß‡•ã‡§ñ‡§æ üò°‡§π‡•à ‡§¨‡§ø‡§®‡§æ ‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä üåé‡§ú‡•Ä...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6720</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§®‡§Ç‡§ó‡•Ä, ‡§π‡•ã‡§ï‡§∞, ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã, ‡§¨‡§®‡§æ‡§ì, ‡§Ö‡§ö‡•ç‡§õ‡•Ä, ‡§≤‡§ó‡•ã‡§ó‡•Ä]</td>\n",
              "      <td>‡§®‡§Ç‡§ó‡•Ä ‡§π‡•ã‡§ï‡§∞ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§¨‡§®‡§æ‡§ì ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§≤‡§ó‡•ã‡§ó‡•Ä</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6721</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§∏‡§π‡•Ä, ‡§§‡§∞‡•Ä‡§ï‡•á, ‡§ï‡§™‡§°‡§º‡•á, ‡§¶‡§ø‡§ñ‡§æ‡§®‡•á, ‡§ï‡•á, ‡§Æ‡•á‡§∞‡•á, ‡§™‡§æ‡§∏, ‡§ï‡§™‡§°‡§º‡§æ]</td>\n",
              "      <td>‡§∏‡§π‡•Ä ‡§§‡§∞‡•Ä‡§ï‡•á ‡§ï‡§™‡§°‡§º‡•á ‡§¶‡§ø‡§ñ‡§æ‡§®‡•á ‡§ï‡•á ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ï‡§™‡§°‡§º‡§æ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6722</th>\n",
              "      <td>1</td>\n",
              "      <td>[‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä, ‡§¶‡•á‡§®, ‡§Æ‡§Ç‡§¶‡§ø‡§∞, ‡§∏‡§¨, ‡§Æ‡§Ç‡§¶‡§ø‡§∞, ‡§∞‡•Å‡§ï‡§µ‡§æ‡§®‡•á, ‡§ï‡§∏‡§∞, ...</td>\n",
              "      <td>‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•á‡§® ‡§Æ‡§Ç‡§¶‡§ø‡§∞ ‡§∏‡§¨ ‡§Æ‡§Ç‡§¶‡§ø‡§∞ ‡§∞‡•Å‡§ï‡§µ‡§æ‡§®‡•á ‡§ï‡§∏‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§õ‡•ã‡§°...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6723</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§Ü‡§∞‡•á, ‡§™‡§æ‡§ó‡§≤, ‡§≤‡§µ‡§°‡•á, ‡§∏‡§Æ‡§ú, ‡§Ü‡§Ø‡•á, ‡§µ‡•ã, ‡§®‡§æ]</td>\n",
              "      <td>‡§Ü‡§∞‡•á ‡§™‡§æ‡§ó‡§≤ ‡§≤‡§µ‡§°‡•á ‡§∏‡§Æ‡§ú ‡§Ü‡§Ø‡•á ‡§µ‡•ã ‡§®‡§æ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6724</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§∂‡•á‡§∞, ‡§®‡•õ‡§∞, ‡§Ö‡§Ç‡§¶‡§æ‡•õ, ‡•§, ‡§ï‡§Æ‡§ú‡•ã‡§∞‡•Ä, ‡§Æ‡§§, ‡§∏‡§Æ‡§ù, ‡§≤‡•á‡§®‡§æ, ‡§§‡•Å...</td>\n",
              "      <td>‡§∂‡•á‡§∞ ‡§®‡•õ‡§∞ ‡§Ö‡§Ç‡§¶‡§æ‡•õ ‡•§ ‡§ï‡§Æ‡§ú‡•ã‡§∞‡•Ä ‡§Æ‡§§ ‡§∏‡§Æ‡§ù ‡§≤‡•á‡§®‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§ï‡•å...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6725</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§≤‡§æ‡§≤, ‡§ö‡§°‡•ç‡§°‡•Ä, ‡§ï‡•á, ‡§≤‡§æ‡§≤, ‡§π‡•ã‡§ó‡§æ]</td>\n",
              "      <td>‡§≤‡§æ‡§≤ ‡§ö‡§°‡•ç‡§°‡•Ä ‡§ï‡•á ‡§≤‡§æ‡§≤ ‡§π‡•ã‡§ó‡§æ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6726</th>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6727</th>\n",
              "      <td>0</td>\n",
              "      <td>[‡§™‡•ã‡§∞‡•Ä‡§ö‡•ç‡§Ø‡§æ, ‡§´‡•ã‡§ü‡•ã, ‡§ï‡§æ‡§Ø, ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú‡§æ‡§Ç‡§ö‡•á, ‡§®‡§æ‡§ü‡§ï, ‡§∞‡•á, ‡§Æ‡§æ...</td>\n",
              "      <td>‡§™‡•ã‡§∞‡•Ä‡§ö‡•ç‡§Ø‡§æ ‡§´‡•ã‡§ü‡•ã ‡§ï‡§æ‡§Ø ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§ü‡§ï ‡§∞‡•á ‡§Æ‡§æ‡§¶‡§∞‡§ö‡•ã‡§§</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14172312-0c28-4478-9581-4663eca0c5f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14172312-0c28-4478-9581-4663eca0c5f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14172312-0c28-4478-9581-4663eca0c5f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPLEMENTATION OF LSTM"
      ],
      "metadata": {
        "id": "EUmHg2pYBJ_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Tokenize(column, seq_len):\n",
        "    ##Create vocabulary of words from column\n",
        "    corpus = [word for text in df['processed_text'] for word in text.split()]\n",
        "    count_words = Counter(corpus)\n",
        "    sorted_words = count_words.most_common()\n",
        "    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "\n",
        "    ##Tokenize the columns text using the vocabulary\n",
        "    text_int = []\n",
        "    for text in column:\n",
        "        r = [vocab_to_int[word] for word in text.split()]\n",
        "        text_int.append(r)\n",
        "    ##Add padding to tokens\n",
        "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    for i, review in enumerate(text_int):\n",
        "        if len(review) <= seq_len:\n",
        "            zeros = list(np.zeros(seq_len - len(review)))\n",
        "            new = zeros + review\n",
        "        else:\n",
        "            new = review[: seq_len]\n",
        "        features[i, :] = np.array(new)\n",
        "\n",
        "    return sorted_words, features\n",
        "\n"
      ],
      "metadata": {
        "id": "4jbnId0XBH1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=100\n",
        "vocabulary, tokenized_column = Tokenize(df[\"processed_text\"], max_len)"
      ],
      "metadata": {
        "id": "-0uyGy6DrIrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_column[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGI9iX_VrSEa",
        "outputId": "13c502c6-efc6-4d9a-8f0b-edc38c1ce75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1248,\n",
              "       1600])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UrYkS65Fsdj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = df['processed_text']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train)"
      ],
      "metadata": {
        "id": "IhxxLiUfsBx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Word2vec_train_data = list(map(lambda x: x.split(), X_train))\n",
        "EMBEDDING_DIM = 200\n"
      ],
      "metadata": {
        "id": "cBGH2kxyrNPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "AMU9EsrOtCWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = Word2Vec(Word2vec_train_data, vector_size=EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "QCxPK49AsxES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocabulary size: {len(vocabulary) + 1}\")"
      ],
      "metadata": {
        "id": "hnSR_EKYBSVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a520df-94ff-4bd5-b666-f6bea1feb9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 32408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(vocabulary) + 1 #+1 for the padding\n"
      ],
      "metadata": {
        "id": "53ai4TxPtSx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define empty embedding matrix\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
        "    \n",
        "#fill the embedding matrix with the pre trained values from word2vec\n",
        "#    corresponding to word (string), token (number associated to the word)\n",
        "for word, token in vocabulary:\n",
        "    if word2vec_model.wv.__contains__(word):\n",
        "        embedding_matrix[token] = word2vec_model.wv.__getitem__(word)\n",
        "\n",
        "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syju4RlAtfUi",
        "outputId": "6f59359a-3a87-48e1-86f7-de10a0edc1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Matrix Shape: (32408, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "X = tokenized_column\n",
        "y = df['label'].values"
      ],
      "metadata": {
        "id": "Drfdw_yltgxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=42)"
      ],
      "metadata": {
        "id": "zKvjwI5dtteL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcwITdTTt2Xg",
        "outputId": "1dc2cc51-a56e-4ce7-8863-e0a967e47415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0, 7579],\n",
              "       [   1, 6952]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "#Tokenization for LSTM\n",
        "from collections import Counter\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "reWipJqguHmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)) #\n",
        "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True) \n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True) #"
      ],
      "metadata": {
        "id": "xb7HApO9t7JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 5 #We are dealing with a multiclass classification of 5 classes\n",
        "HIDDEN_DIM = 100 #number of neurons of the internal state (internal neural network in the LSTM)\n",
        "LSTM_LAYERS = 1 #Number of stacked LSTM layers\n",
        "\n",
        "LR = 3e-4 #Learning rate\n",
        "DROPOUT = 0.5 #LSTM Dropout\n",
        "BIDIRECTIONAL = True #Boolean value to choose if to use a bidirectional LSTM or not\n",
        "EPOCHS = 10 #Number of training epoch\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "class BiLSTM_Sentiment_Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, lstm_layers, bidirectional,batch_size, dropout):\n",
        "        super(BiLSTM_Sentiment_Classifier,self).__init__()\n",
        "        \n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers=lstm_layers,\n",
        "                            dropout=dropout,\n",
        "                            bidirectional=bidirectional,\n",
        "                            batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim*self.num_directions, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        self.batch_size = x.size(0)\n",
        "        ##EMBEDDING LAYER\n",
        "        embedded = self.embedding(x)\n",
        "        #LSTM LAYERS\n",
        "        out, hidden = self.lstm(embedded, hidden)\n",
        "        #Extract only the hidden state from the last LSTM cell\n",
        "        out = out[:,-1,:]\n",
        "        #FULLY CONNECTED LAYERS\n",
        "        out = self.fc(out)\n",
        "        out = self.softmax(out)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        #Initialization of the LSTM hidden and cell states\n",
        "        h0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n",
        "        c0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n",
        "        hidden = (h0, c0)\n",
        "        return hidden\n",
        "model = BiLSTM_Sentiment_Classifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM,NUM_CLASSES, LSTM_LAYERS,BIDIRECTIONAL, BATCH_SIZE, DROPOUT)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "#Initialize embedding with the previously defined embedding matrix\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "#Allow the embedding matrix to be fined tuned to better adapt to out dataset and get higher accuracy\n",
        "model.embedding.weight.requires_grad=True\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6VB5W0iuTBY",
        "outputId": "96ca60b1-0d23-4bb8-ae3d-4e21463f1d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiLSTM_Sentiment_Classifier(\n",
            "  (embedding): Embedding(32408, 200)\n",
            "  (lstm): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay = 5e-6)"
      ],
      "metadata": {
        "id": "hxkDtJLluo0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Below cell is for trainig if dont want to train dont run it"
      ],
      "metadata": {
        "id": "kC50B-50QeoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "total_step_val = len(valid_loader)\n",
        "\n",
        "early_stopping_patience = 4\n",
        "early_stopping_counter = 0\n",
        "\n",
        "valid_acc_max = 0 # Initialize best accuracy top 0\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "\n",
        "    #lists to host the train and validation losses of every batch for each epoch\n",
        "    train_loss, valid_loss  = [], []\n",
        "    #lists to host the train and validation accuracy of every batch for each epoch\n",
        "    train_acc, valid_acc  = [], []\n",
        "\n",
        "    #lists to host the train and validation predictions of every batch for each epoch\n",
        "    y_train_list, y_val_list = [], []\n",
        "\n",
        "    #initalize number of total and correctly classified texts during training and validation\n",
        "    correct, correct_val = 0, 0\n",
        "    total, total_val = 0, 0\n",
        "    running_loss, running_loss_val = 0, 0\n",
        "\n",
        "\n",
        "    ####TRAINING LOOP####\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE) #load features and targets in device\n",
        "\n",
        "        h = model.init_hidden(labels.size(0))\n",
        "\n",
        "        model.zero_grad() #reset gradients \n",
        "\n",
        "        output, h = model(inputs,h) #get output and hidden states from LSTM network\n",
        "        \n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred_train = torch.argmax(output, dim=1) #get tensor of predicted values on the training set\n",
        "        y_train_list.extend(y_pred_train.squeeze().tolist()) #transform tensor to list and the values to the list\n",
        "        \n",
        "        correct += torch.sum(y_pred_train==labels).item() #count correctly classified texts per batch\n",
        "        total += labels.size(0) #count total texts per batch\n",
        "\n",
        "    train_loss.append(running_loss / total_step)\n",
        "    train_acc.append(100 * correct / total)\n",
        "\n",
        "    ####VALIDATION LOOP####\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        model.eval()\n",
        "        \n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            val_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "\n",
        "            val_loss = criterion(output, labels)\n",
        "            running_loss_val += val_loss.item()\n",
        "\n",
        "            y_pred_val = torch.argmax(output, dim=1)\n",
        "            y_val_list.extend(y_pred_val.squeeze().tolist())\n",
        "\n",
        "            correct_val += torch.sum(y_pred_val==labels).item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "        valid_loss.append(running_loss_val / total_step_val)\n",
        "        valid_acc.append(100 * correct_val / total_val)\n",
        "\n",
        "    #Save model if validation accuracy increases\n",
        "    if np.mean(valid_acc) >= valid_acc_max:\n",
        "        torch.save(model.state_dict(), './lstm_model.pth')\n",
        "        print(f'Epoch {e+1}:Validation accuracy increased ({valid_acc_max:.6f} --> {np.mean(valid_acc):.6f}).  Saving model ...')\n",
        "        valid_acc_max = np.mean(valid_acc)\n",
        "        early_stopping_counter=0 #reset counter if validation accuracy increases\n",
        "    else:\n",
        "        print(f'Epoch {e+1}:Validation accuracy did not increase')\n",
        "        early_stopping_counter+=1 #increase counter if validation accuracy does not increase\n",
        "        \n",
        "    if early_stopping_counter > early_stopping_patience:\n",
        "        print('Early stopped at epoch :', e+1)\n",
        "        break\n",
        "    \n",
        "    print(f'\\tTrain_loss : {np.mean(train_loss):.4f} Val_loss : {np.mean(valid_loss):.4f}')\n",
        "    print(f'\\tTrain_acc : {np.mean(train_acc):.3f}% Val_acc : {np.mean(valid_acc):.3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_5ZLHvGuq6X",
        "outputId": "12c7887e-7bfe-420e-90d5-c70af920c744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:Validation accuracy increased (0.000000 --> 73.312500).  Saving model ...\n",
            "\tTrain_loss : 0.7472 Val_loss : 0.6180\n",
            "\tTrain_acc : 55.789% Val_acc : 73.312%\n",
            "Epoch 2:Validation accuracy increased (73.312500 --> 79.000000).  Saving model ...\n",
            "\tTrain_loss : 0.4364 Val_loss : 0.4484\n",
            "\tTrain_acc : 82.358% Val_acc : 79.000%\n",
            "Epoch 3:Validation accuracy increased (79.000000 --> 80.437500).  Saving model ...\n",
            "\tTrain_loss : 0.2279 Val_loss : 0.4742\n",
            "\tTrain_acc : 91.795% Val_acc : 80.438%\n",
            "Epoch 4:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.1351 Val_loss : 0.4992\n",
            "\tTrain_acc : 95.457% Val_acc : 79.312%\n",
            "Epoch 5:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0875 Val_loss : 0.5679\n",
            "\tTrain_acc : 97.212% Val_acc : 79.750%\n",
            "Epoch 6:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0632 Val_loss : 0.6319\n",
            "\tTrain_acc : 98.259% Val_acc : 78.875%\n",
            "Epoch 7:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0503 Val_loss : 0.7072\n",
            "\tTrain_acc : 98.596% Val_acc : 79.375%\n",
            "Epoch 8:Validation accuracy did not increase\n",
            "Early stopped at epoch : 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Model"
      ],
      "metadata": {
        "id": "jhCm0jdKQroD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTM_Sentiment_Classifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM,NUM_CLASSES, LSTM_LAYERS,BIDIRECTIONAL, BATCH_SIZE, DROPOUT)\n",
        "model = model.to(DEVICE)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/22CS60R37_A8 DL/lstm_model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY9Wq4Yeu9nP",
        "outputId": "28dfd280-17d6-41e7-d135-0568f3ed7886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating our model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iDFHfUI2QvkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred_list = []\n",
        "y_test_list = []\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "    test_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "    output, val_h = model(inputs, test_h)\n",
        "    y_pred_test = torch.argmax(output, dim=1)\n",
        "    y_pred_list.extend(y_pred_test.squeeze().tolist())\n",
        "    y_test_list.extend(labels.squeeze().tolist())"
      ],
      "metadata": {
        "id": "n2clEOz0vD4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing Accuracy Report of Trained Model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U2IZa26iQ1BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "rwCawoyNvSw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report for LSTM :\\n', classification_report(y_test_list, y_pred_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa1apPgYvP8z",
        "outputId": "4f19fc95-961a-49a8-9f0c-2aae9ffe84b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for LSTM :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.78      0.81      2102\n",
            "           1       0.78      0.84      0.81      1930\n",
            "\n",
            "    accuracy                           0.81      4032\n",
            "   macro avg       0.81      0.81      0.81      4032\n",
            "weighted avg       0.81      0.81      0.81      4032\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test_list,y_pred_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G6879aFv79I",
        "outputId": "61d191b1-318d-47cc-f477-077af240dbd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1648,  454],\n",
              "       [ 315, 1615]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing for given Test.csv File\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3WoGsG5Ox3zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Tokenize(column, seq_len):\n",
        "    ##Create vocabulary of words from column\n",
        "    corpus = [word for text in tdf['tprocessed_text'] for word in text.split()]\n",
        "    count_words = Counter(corpus)\n",
        "    sorted_words = count_words.most_common()\n",
        "    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "\n",
        "    ##Tokenize the columns text using the vocabulary\n",
        "    text_int = []\n",
        "    for text in column:\n",
        "        r = [vocab_to_int[word] for word in text.split()]\n",
        "        text_int.append(r)\n",
        "    ##Add padding to tokens\n",
        "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    for i, review in enumerate(text_int):\n",
        "        if len(review) <= seq_len:\n",
        "            zeros = list(np.zeros(seq_len - len(review)))\n",
        "            new = zeros + review\n",
        "        else:\n",
        "            new = review[: seq_len]\n",
        "        features[i, :] = np.array(new)\n",
        "\n",
        "    return sorted_words, features\n",
        "\n"
      ],
      "metadata": {
        "id": "8SV_fwzQ83-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tdf['tprocessed_text']\n",
        "y = tdf['label']\n",
        "\n",
        "vocabulary, tokenized_column = Tokenize(tdf[\"tprocessed_text\"], max_len)\n",
        "\n",
        "X = tokenized_column\n",
        "y = tdf['label'].values\n",
        "\n",
        "test_data = TensorDataset(torch.from_numpy(X), torch.from_numpy(y))\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True) #\n",
        "\n",
        "model.eval()\n",
        "y_pred_list = []\n",
        "y_test_list = []\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "    test_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "    output, val_h = model(inputs, test_h)\n",
        "    y_pred_test = torch.argmax(output, dim=1)\n",
        "    y_pred_list.extend(y_pred_test.squeeze().tolist())\n",
        "    y_test_list.extend(labels.squeeze().tolist())"
      ],
      "metadata": {
        "id": "lEGGtQH5x2pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing Classification report of Test Dataset"
      ],
      "metadata": {
        "id": "ZgRgKNODRIlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report for LSTM :\\n', classification_report(y_test_list, y_pred_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px0fPuxTzXnQ",
        "outputId": "66ee5965-44fc-41e9-ffc7-a98c534cd21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for LSTM :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.90      0.92      1051\n",
            "           1       0.89      0.94      0.92       933\n",
            "\n",
            "    accuracy                           0.92      1984\n",
            "   macro avg       0.92      0.92      0.92      1984\n",
            "weighted avg       0.92      0.92      0.92      1984\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_intersection_points(train_df, val_df, new_testdf):\n",
        "  train_com_count = 0\n",
        "  val_com_count = 0\n",
        "  for sentence in train_df['text']:\n",
        "    for new_sentence in new_testdf['text']:\n",
        "      if sentence==new_sentence:\n",
        "        train_com_count += 1\n",
        "\n",
        "  for sentence in val_df['text']:\n",
        "    for new_sentence in new_testdf['text']:\n",
        "      if sentence==new_sentence:\n",
        "        val_com_count += 1\n",
        "  \n",
        "  # print(\"Intersection points for dataset used for testing and training \", modelname)\n",
        "  print(\"Common points with training dataset: \",train_com_count)\n",
        "  print(\"Common points with validation dataset: \",val_com_count)\n",
        "\n",
        "print_intersection_points(traindf, valdf, test_df)\n"
      ],
      "metadata": {
        "id": "Jn6i7ridNx3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176be1c4-3944-4556-afc9-5a7aea86591a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common points with training dataset:  166\n",
            "Common points with validation dataset:  56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWQySlOJ-Rqj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}